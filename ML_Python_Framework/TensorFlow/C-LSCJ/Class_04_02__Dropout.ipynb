{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Load Data`**\n",
    "+ `one-hot` format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-83231f068ae1>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /home/local/SPREADTRUM/xing.jian/Public/Soft/Anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /home/local/SPREADTRUM/xing.jian/Public/Soft/Anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /home/local/SPREADTRUM/xing.jian/Public/Soft/Anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/local/SPREADTRUM/xing.jian/Public/Soft/Anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/local/SPREADTRUM/xing.jian/Public/Soft/Anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape : (55000, 784)\n",
      "Y_train.shape : (55000, 10)\n"
     ]
    }
   ],
   "source": [
    "print('X_train.shape :', mnist.train.images.shape)\n",
    "print('Y_train.shape :', mnist.train.labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "n_batch = mnist.train.num_examples // batch_size  # 整除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "y = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Dropout Param`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Weight_L1 = tf.Variable(tf.truncated_normal([784,2000], stddev=0.1))  # (input, output)\n",
    "Biases_L1 = tf.Variable(tf.zeros([2000]) + 0.1)\n",
    "Z_L1 = tf.matmul(x, Weight_L1) + Biases_L1\n",
    "A_L1 = tf.nn.tanh(Z_L1)\n",
    "\n",
    "Drop_L1 = tf.nn.dropout(A_L1, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Weight_L2 = tf.Variable(tf.truncated_normal([2000,2000], stddev=0.1))  # (input, output)\n",
    "Biases_L2 = tf.Variable(tf.zeros([2000]) + 0.1)\n",
    "Z_L2 = tf.matmul(Drop_L1, Weight_L2) + Biases_L2\n",
    "A_L2 = tf.nn.tanh(Z_L2)\n",
    "\n",
    "Drop_L2 = tf.nn.dropout(A_L2, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Weight_L3 = tf.Variable(tf.truncated_normal([2000,1000], stddev=0.1))  # (input, output)\n",
    "Biases_L3 = tf.Variable(tf.zeros([1000]) + 0.1)\n",
    "Z_L3 = tf.matmul(Drop_L2, Weight_L3) + Biases_L3\n",
    "A_L3 = tf.nn.tanh(Z_L3)\n",
    "\n",
    "Drop_L3 = tf.nn.dropout(A_L3, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Weight_L4 = tf.Variable(tf.truncated_normal([1000,10], stddev=0.1))  # (input, output)\n",
    "Biases_L4 = tf.Variable(tf.zeros([10]) + 0.1)\n",
    "Z_L4 = tf.matmul(Drop_L3, Weight_L4) + Biases_L4\n",
    "A_L4 = tf.nn.softmax(Z_L4)\n",
    "\n",
    "Prediction = tf.nn.softmax(Z_L4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-11-2bba27c49a47>:1: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=Prediction))\n",
    "\n",
    "lr = tf.Variable(0.3)\n",
    "optimizer = tf.train.GradientDescentOptimizer(lr)\n",
    "train = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(Prediction, 1))\n",
    "accuary = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**由于该神经网络过于复杂，容易出现overfitting**\n",
    "+ 因此使用dropout来避免过拟合\n",
    "+ 当使用dropout之后\n",
    "    + test accuracy的上升速度变慢，[ 从 96 -> 97 ]， 收敛速度变慢\n",
    "    + **train accuracy的准确率没有很高**，**test & train accuracy 相对偏差不是很大**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0  Test Acuuary 0.8616  Train Acuuary 0.8703273\n",
      "Iter 1  Test Acuuary 0.8689  Train Acuuary 0.8832\n",
      "Iter 2  Test Acuuary 0.8748  Train Acuuary 0.88905454\n",
      "Iter 3  Test Acuuary 0.8756  Train Acuuary 0.8920909\n",
      "Iter 4  Test Acuuary 0.9651  Train Acuuary 0.98309094\n",
      "Iter 5  Test Acuuary 0.9674  Train Acuuary 0.99012727\n",
      "Iter 6  Test Acuuary 0.9712  Train Acuuary 0.99227273\n",
      "Iter 7  Test Acuuary 0.9717  Train Acuuary 0.9931818\n",
      "Iter 8  Test Acuuary 0.9727  Train Acuuary 0.99381816\n",
      "Iter 9  Test Acuuary 0.9729  Train Acuuary 0.99423635\n",
      "Iter 10  Test Acuuary 0.9723  Train Acuuary 0.9946727\n",
      "Iter 11  Test Acuuary 0.973  Train Acuuary 0.99487275\n",
      "Iter 12  Test Acuuary 0.9736  Train Acuuary 0.9951091\n",
      "Iter 13  Test Acuuary 0.9739  Train Acuuary 0.9954\n",
      "Iter 14  Test Acuuary 0.9741  Train Acuuary 0.9955091\n",
      "Iter 15  Test Acuuary 0.974  Train Acuuary 0.9956\n",
      "Iter 16  Test Acuuary 0.9743  Train Acuuary 0.9956909\n",
      "Iter 17  Test Acuuary 0.9746  Train Acuuary 0.99576366\n",
      "Iter 18  Test Acuuary 0.9741  Train Acuuary 0.99585456\n",
      "Iter 19  Test Acuuary 0.9741  Train Acuuary 0.99594545\n",
      "Iter 20  Test Acuuary 0.9747  Train Acuuary 0.9959818\n",
      "Iter 21  Test Acuuary 0.9746  Train Acuuary 0.9959818\n",
      "Iter 22  Test Acuuary 0.9747  Train Acuuary 0.9960727\n",
      "Iter 23  Test Acuuary 0.9748  Train Acuuary 0.99610907\n",
      "Iter 24  Test Acuuary 0.9747  Train Acuuary 0.99612725\n",
      "Iter 25  Test Acuuary 0.975  Train Acuuary 0.9962\n",
      "Iter 26  Test Acuuary 0.9745  Train Acuuary 0.9962909\n",
      "Iter 27  Test Acuuary 0.9747  Train Acuuary 0.9963273\n",
      "Iter 28  Test Acuuary 0.9752  Train Acuuary 0.99634546\n",
      "Iter 29  Test Acuuary 0.9749  Train Acuuary 0.9963818\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(30):\n",
    "        for batch in range(n_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            sess.run(train, feed_dict={\n",
    "                x : batch_xs,\n",
    "                y : batch_ys,\n",
    "                keep_prob : 1.0\n",
    "            })\n",
    "            # keep_prob\n",
    "            # 1.0 : 所有神经元都在使用\n",
    "            \n",
    "        test_acc = sess.run(accuary, feed_dict={\n",
    "            x:mnist.test.images,\n",
    "            y:mnist.test.labels,\n",
    "            keep_prob : 1.0\n",
    "        })\n",
    "        train_acc = sess.run(accuary, feed_dict={\n",
    "            x:mnist.train.images,\n",
    "            y:mnist.train.labels,\n",
    "            keep_prob : 1.0\n",
    "        })\n",
    "\n",
    "        print(\"Iter \" + str(epoch) + \"  Test Acuuary \" + str(test_acc) + \"  Train Acuuary \" + str(train_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0  Test Acuuary 0.9228  Train Acuuary 0.91761816\n",
      "Iter 1  Test Acuuary 0.9367  Train Acuuary 0.92981815\n",
      "Iter 2  Test Acuuary 0.9407  Train Acuuary 0.9398364\n",
      "Iter 3  Test Acuuary 0.945  Train Acuuary 0.9450182\n",
      "Iter 4  Test Acuuary 0.9473  Train Acuuary 0.94823635\n",
      "Iter 5  Test Acuuary 0.951  Train Acuuary 0.95214546\n",
      "Iter 6  Test Acuuary 0.9535  Train Acuuary 0.9557273\n",
      "Iter 7  Test Acuuary 0.9544  Train Acuuary 0.9574\n",
      "Iter 8  Test Acuuary 0.9553  Train Acuuary 0.95927274\n",
      "Iter 9  Test Acuuary 0.9575  Train Acuuary 0.96154547\n",
      "Iter 10  Test Acuuary 0.9604  Train Acuuary 0.96385455\n",
      "Iter 11  Test Acuuary 0.961  Train Acuuary 0.96445453\n",
      "Iter 12  Test Acuuary 0.9621  Train Acuuary 0.96596366\n",
      "Iter 13  Test Acuuary 0.9635  Train Acuuary 0.96785456\n",
      "Iter 14  Test Acuuary 0.9635  Train Acuuary 0.96894544\n",
      "Iter 15  Test Acuuary 0.9637  Train Acuuary 0.96985453\n",
      "Iter 16  Test Acuuary 0.9649  Train Acuuary 0.971\n",
      "Iter 17  Test Acuuary 0.967  Train Acuuary 0.972\n",
      "Iter 18  Test Acuuary 0.9665  Train Acuuary 0.97205454\n",
      "Iter 19  Test Acuuary 0.9684  Train Acuuary 0.9734727\n",
      "Iter 20  Test Acuuary 0.9675  Train Acuuary 0.9745091\n",
      "Iter 21  Test Acuuary 0.9692  Train Acuuary 0.97505456\n",
      "Iter 22  Test Acuuary 0.9691  Train Acuuary 0.9756\n",
      "Iter 23  Test Acuuary 0.9699  Train Acuuary 0.97678185\n",
      "Iter 24  Test Acuuary 0.9705  Train Acuuary 0.97705454\n",
      "Iter 25  Test Acuuary 0.9707  Train Acuuary 0.97801816\n",
      "Iter 26  Test Acuuary 0.9713  Train Acuuary 0.9777091\n",
      "Iter 27  Test Acuuary 0.9711  Train Acuuary 0.9787273\n",
      "Iter 28  Test Acuuary 0.9723  Train Acuuary 0.9791091\n",
      "Iter 29  Test Acuuary 0.9721  Train Acuuary 0.97990906\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(30):\n",
    "        for batch in range(n_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            sess.run(train, feed_dict={\n",
    "                x : batch_xs,\n",
    "                y : batch_ys,\n",
    "                keep_prob : 0.7\n",
    "            })\n",
    "            \n",
    "        test_acc = sess.run(accuary, feed_dict={\n",
    "            x:mnist.test.images,\n",
    "            y:mnist.test.labels,\n",
    "            keep_prob : 1.0\n",
    "        })\n",
    "        train_acc = sess.run(accuary, feed_dict={\n",
    "            x:mnist.train.images,\n",
    "            y:mnist.train.labels,\n",
    "            keep_prob : 1.0\n",
    "        })\n",
    "\n",
    "        print(\"Iter \" + str(epoch) + \"  Test Acuuary \" + str(test_acc) + \"  Train Acuuary \" + str(train_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
