{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Load Data`**\n",
    "+ `one-hot` format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-83231f068ae1>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /home/local/SPREADTRUM/xing.jian/Public/Soft/Anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /home/local/SPREADTRUM/xing.jian/Public/Soft/Anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /home/local/SPREADTRUM/xing.jian/Public/Soft/Anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/local/SPREADTRUM/xing.jian/Public/Soft/Anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/local/SPREADTRUM/xing.jian/Public/Soft/Anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape : (55000, 784)\n",
      "Y_train.shape : (55000, 10)\n"
     ]
    }
   ],
   "source": [
    "print('X_train.shape :', mnist.train.images.shape)\n",
    "print('Y_train.shape :', mnist.train.labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "n_batch = mnist.train.num_examples // batch_size  # 整除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "y = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Weight_L1 = tf.Variable(tf.truncated_normal([784,300], stddev=0.1))  # (input, output)\n",
    "Biases_L1 = tf.Variable(tf.zeros([300]) + 0.1)\n",
    "Z_L1 = tf.matmul(x, Weight_L1) + Biases_L1\n",
    "A_L1 = tf.nn.tanh(Z_L1)\n",
    "\n",
    "Drop_L1 = tf.nn.dropout(A_L1, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Weight_L2 = tf.Variable(tf.truncated_normal([300,100], stddev=0.1))  # (input, output)\n",
    "Biases_L2 = tf.Variable(tf.zeros([100]) + 0.1)\n",
    "Z_L2 = tf.matmul(Drop_L1, Weight_L2) + Biases_L2\n",
    "A_L2 = tf.nn.tanh(Z_L2)\n",
    "\n",
    "Drop_L2 = tf.nn.dropout(A_L2, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Weight_L3 = tf.Variable(tf.truncated_normal([100,10], stddev=0.1))  # (input, output)\n",
    "Biases_L3 = tf.Variable(tf.zeros([10]) + 0.1)\n",
    "Z_L3 = tf.matmul(Drop_L2, Weight_L3) + Biases_L3\n",
    "A_L3 = tf.nn.softmax(Z_L3)\n",
    "\n",
    "Prediction = tf.nn.softmax(Z_L3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y, logits=Prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Optimizer`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = tf.Variable(0.001) # 1e-3\n",
    "\n",
    "# optimizer = tf.train.GradientDescentOptimizer(lr)\n",
    "optimizer = tf.train.AdamOptimizer(lr)\n",
    "\n",
    "train = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(Prediction, 1))\n",
    "accuary = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0  Test Acuuary 0.9428  Train Acuuary 0.9434364\n",
      "Iter 1  Test Acuuary 0.958  Train Acuuary 0.96523637\n",
      "Iter 2  Test Acuuary 0.965  Train Acuuary 0.9729091\n",
      "Iter 3  Test Acuuary 0.9626  Train Acuuary 0.97312725\n",
      "Iter 4  Test Acuuary 0.9722  Train Acuuary 0.9830545\n",
      "Iter 5  Test Acuuary 0.9704  Train Acuuary 0.9835455\n",
      "Iter 6  Test Acuuary 0.9744  Train Acuuary 0.98521817\n",
      "Iter 7  Test Acuuary 0.974  Train Acuuary 0.9884909\n",
      "Iter 8  Test Acuuary 0.973  Train Acuuary 0.9894182\n",
      "Iter 9  Test Acuuary 0.9744  Train Acuuary 0.99\n",
      "Iter 10  Test Acuuary 0.9744  Train Acuuary 0.9899455\n",
      "Iter 11  Test Acuuary 0.9764  Train Acuuary 0.9926182\n",
      "Iter 12  Test Acuuary 0.9737  Train Acuuary 0.9919818\n",
      "Iter 13  Test Acuuary 0.977  Train Acuuary 0.99314547\n",
      "Iter 14  Test Acuuary 0.9786  Train Acuuary 0.99349093\n",
      "Iter 15  Test Acuuary 0.9767  Train Acuuary 0.9937091\n",
      "Iter 16  Test Acuuary 0.9778  Train Acuuary 0.9932727\n",
      "Iter 17  Test Acuuary 0.9774  Train Acuuary 0.9935273\n",
      "Iter 18  Test Acuuary 0.98  Train Acuuary 0.99472725\n",
      "Iter 19  Test Acuuary 0.978  Train Acuuary 0.9951091\n",
      "Iter 20  Test Acuuary 0.9805  Train Acuuary 0.99447274\n",
      "Iter 21  Test Acuuary 0.9789  Train Acuuary 0.9945091\n",
      "Iter 22  Test Acuuary 0.9777  Train Acuuary 0.9950727\n",
      "Iter 23  Test Acuuary 0.9791  Train Acuuary 0.99496365\n",
      "Iter 24  Test Acuuary 0.979  Train Acuuary 0.99596363\n",
      "Iter 25  Test Acuuary 0.9756  Train Acuuary 0.9942909\n",
      "Iter 26  Test Acuuary 0.9764  Train Acuuary 0.9954909\n",
      "Iter 27  Test Acuuary 0.9788  Train Acuuary 0.99594545\n",
      "Iter 28  Test Acuuary 0.9799  Train Acuuary 0.9956727\n",
      "Iter 29  Test Acuuary 0.9774  Train Acuuary 0.99554545\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(30):\n",
    "        for batch in range(n_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            sess.run(train, feed_dict={\n",
    "                x : batch_xs,\n",
    "                y : batch_ys,\n",
    "                keep_prob : 1.0\n",
    "            })\n",
    "            \n",
    "        test_acc = sess.run(accuary, feed_dict={\n",
    "            x:mnist.test.images,\n",
    "            y:mnist.test.labels,\n",
    "            keep_prob : 1.0\n",
    "        })\n",
    "        train_acc = sess.run(accuary, feed_dict={\n",
    "            x:mnist.train.images,\n",
    "            y:mnist.train.labels,\n",
    "            keep_prob : 1.0\n",
    "        })\n",
    "\n",
    "        print(\"Iter \" + str(epoch) + \"  Test Acuuary \" + str(test_acc) + \"  Train Acuuary \" + str(train_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0  Test Acuuary 0.933  Train Acuuary 0.93096364\n",
      "Iter 1  Test Acuuary 0.9452  Train Acuuary 0.9469454\n",
      "Iter 2  Test Acuuary 0.9543  Train Acuuary 0.9570909\n",
      "Iter 3  Test Acuuary 0.9576  Train Acuuary 0.9602727\n",
      "Iter 4  Test Acuuary 0.9595  Train Acuuary 0.9642\n",
      "Iter 5  Test Acuuary 0.9627  Train Acuuary 0.9675636\n",
      "Iter 6  Test Acuuary 0.965  Train Acuuary 0.9709273\n",
      "Iter 7  Test Acuuary 0.9632  Train Acuuary 0.972\n",
      "Iter 8  Test Acuuary 0.9666  Train Acuuary 0.9744727\n",
      "Iter 9  Test Acuuary 0.9677  Train Acuuary 0.9763455\n",
      "Iter 10  Test Acuuary 0.9681  Train Acuuary 0.97745454\n",
      "Iter 11  Test Acuuary 0.9677  Train Acuuary 0.97827274\n",
      "Iter 12  Test Acuuary 0.97  Train Acuuary 0.97923636\n",
      "Iter 13  Test Acuuary 0.9717  Train Acuuary 0.9803636\n",
      "Iter 14  Test Acuuary 0.9722  Train Acuuary 0.9815091\n",
      "Iter 15  Test Acuuary 0.9704  Train Acuuary 0.9813273\n",
      "Iter 16  Test Acuuary 0.9734  Train Acuuary 0.98254544\n",
      "Iter 17  Test Acuuary 0.9723  Train Acuuary 0.98274547\n",
      "Iter 18  Test Acuuary 0.9725  Train Acuuary 0.9837273\n",
      "Iter 19  Test Acuuary 0.973  Train Acuuary 0.9841273\n",
      "Iter 20  Test Acuuary 0.9743  Train Acuuary 0.9846909\n",
      "Iter 21  Test Acuuary 0.9745  Train Acuuary 0.9851091\n",
      "Iter 22  Test Acuuary 0.9734  Train Acuuary 0.9856182\n",
      "Iter 23  Test Acuuary 0.9734  Train Acuuary 0.98554546\n",
      "Iter 24  Test Acuuary 0.975  Train Acuuary 0.9863273\n",
      "Iter 25  Test Acuuary 0.9752  Train Acuuary 0.98703635\n",
      "Iter 26  Test Acuuary 0.9746  Train Acuuary 0.9870727\n",
      "Iter 27  Test Acuuary 0.9756  Train Acuuary 0.98734546\n",
      "Iter 28  Test Acuuary 0.9744  Train Acuuary 0.98701817\n",
      "Iter 29  Test Acuuary 0.9743  Train Acuuary 0.9874727\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(30):\n",
    "        for batch in range(n_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            sess.run(train, feed_dict={\n",
    "                x : batch_xs,\n",
    "                y : batch_ys,\n",
    "                keep_prob : 0.7\n",
    "            })\n",
    "            \n",
    "        test_acc = sess.run(accuary, feed_dict={\n",
    "            x:mnist.test.images,\n",
    "            y:mnist.test.labels,\n",
    "            keep_prob : 1.0\n",
    "        })\n",
    "        train_acc = sess.run(accuary, feed_dict={\n",
    "            x:mnist.train.images,\n",
    "            y:mnist.train.labels,\n",
    "            keep_prob : 1.0\n",
    "        })\n",
    "\n",
    "        print(\"Iter \" + str(epoch) + \"  Test Acuuary \" + str(test_acc) + \"  Train Acuuary \" + str(train_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
