{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Load Data`**\n",
    "+ `one-hot` format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-83231f068ae1>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /home/local/SPREADTRUM/xing.jian/Public/Soft/Anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /home/local/SPREADTRUM/xing.jian/Public/Soft/Anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /home/local/SPREADTRUM/xing.jian/Public/Soft/Anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/local/SPREADTRUM/xing.jian/Public/Soft/Anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/local/SPREADTRUM/xing.jian/Public/Soft/Anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape : (55000, 784)\n",
      "Y_train.shape : (55000, 10)\n"
     ]
    }
   ],
   "source": [
    "print('X_train.shape :', mnist.train.images.shape)\n",
    "print('Y_train.shape :', mnist.train.labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "n_batch = mnist.train.num_examples // batch_size  # 整除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "y = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Weight_L1 = tf.Variable(tf.truncated_normal([784,500], stddev=0.1))  # (input, output)\n",
    "Biases_L1 = tf.Variable(tf.zeros([500]) + 0.1)\n",
    "Z_L1 = tf.matmul(x, Weight_L1) + Biases_L1\n",
    "A_L1 = tf.nn.tanh(Z_L1)\n",
    "\n",
    "Drop_L1 = tf.nn.dropout(A_L1, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Weight_L2 = tf.Variable(tf.truncated_normal([500,300], stddev=0.1))  # (input, output)\n",
    "Biases_L2 = tf.Variable(tf.zeros([300]) + 0.1)\n",
    "Z_L2 = tf.matmul(Drop_L1, Weight_L2) + Biases_L2\n",
    "A_L2 = tf.nn.tanh(Z_L2)\n",
    "\n",
    "Drop_L2 = tf.nn.dropout(A_L2, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Weight_L3 = tf.Variable(tf.truncated_normal([300,10], stddev=0.1))  # (input, output)\n",
    "Biases_L3 = tf.Variable(tf.zeros([10]) + 0.1)\n",
    "Z_L3 = tf.matmul(Drop_L2, Weight_L3) + Biases_L3\n",
    "A_L3 = tf.nn.softmax(Z_L3)\n",
    "\n",
    "Prediction = tf.nn.softmax(Z_L3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y, logits=Prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Optimizer`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = tf.Variable(0.001) # 1e-3\n",
    "\n",
    "# optimizer = tf.train.GradientDescentOptimizer(lr)\n",
    "optimizer = tf.train.AdamOptimizer(lr)\n",
    "\n",
    "train = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(Prediction, 1))\n",
    "    # return a bool-list\n",
    "\n",
    "accuary = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**由于该神经网络过于复杂，容易出现overfitting**\n",
    "+ 因此使用dropout来避免过拟合\n",
    "+ 当使用dropout之后\n",
    "    + test accuracy的上升速度变慢，[ 从 96 -> 97 ]， 收敛速度变慢\n",
    "    + **train accuracy的准确率没有很高**，**test & train accuracy 相对偏差不是很大**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0  Test Acuuary 0.9428  Train Acuuary 0.9465455 Learning Rate 0.001\n",
      "Iter 1  Test Acuuary 0.9564  Train Acuuary 0.9608727 Learning Rate 0.00095\n",
      "Iter 2  Test Acuuary 0.9633  Train Acuuary 0.96950907 Learning Rate 0.0009025\n",
      "Iter 3  Test Acuuary 0.9665  Train Acuuary 0.9735818 Learning Rate 0.000857375\n",
      "Iter 4  Test Acuuary 0.9677  Train Acuuary 0.9766545 Learning Rate 0.00081450626\n",
      "Iter 5  Test Acuuary 0.9732  Train Acuuary 0.98063636 Learning Rate 0.0007737809\n",
      "Iter 6  Test Acuuary 0.9711  Train Acuuary 0.9826364 Learning Rate 0.0007350919\n",
      "Iter 7  Test Acuuary 0.973  Train Acuuary 0.98352724 Learning Rate 0.0006983373\n",
      "Iter 8  Test Acuuary 0.9758  Train Acuuary 0.9855273 Learning Rate 0.0006634204\n",
      "Iter 9  Test Acuuary 0.9748  Train Acuuary 0.9868364 Learning Rate 0.0006302494\n",
      "Iter 10  Test Acuuary 0.9758  Train Acuuary 0.9887273 Learning Rate 0.0005987369\n",
      "Iter 11  Test Acuuary 0.9768  Train Acuuary 0.98923635 Learning Rate 0.0005688001\n",
      "Iter 12  Test Acuuary 0.9752  Train Acuuary 0.9898 Learning Rate 0.0005403601\n",
      "Iter 13  Test Acuuary 0.9771  Train Acuuary 0.99070907 Learning Rate 0.0005133421\n",
      "Iter 14  Test Acuuary 0.9785  Train Acuuary 0.99161816 Learning Rate 0.000487675\n",
      "Iter 15  Test Acuuary 0.978  Train Acuuary 0.99169093 Learning Rate 0.00046329122\n",
      "Iter 16  Test Acuuary 0.9781  Train Acuuary 0.9922 Learning Rate 0.00044012666\n",
      "Iter 17  Test Acuuary 0.9791  Train Acuuary 0.99314547 Learning Rate 0.00041812033\n",
      "Iter 18  Test Acuuary 0.9799  Train Acuuary 0.9931818 Learning Rate 0.00039721432\n",
      "Iter 19  Test Acuuary 0.9784  Train Acuuary 0.9935091 Learning Rate 0.0003773536\n",
      "Iter 20  Test Acuuary 0.9794  Train Acuuary 0.99372727 Learning Rate 0.00035848594\n",
      "Iter 21  Test Acuuary 0.9797  Train Acuuary 0.99423635 Learning Rate 0.00034056162\n",
      "Iter 22  Test Acuuary 0.9817  Train Acuuary 0.9943454 Learning Rate 0.00032353355\n",
      "Iter 23  Test Acuuary 0.9812  Train Acuuary 0.99472725 Learning Rate 0.00030735688\n",
      "Iter 24  Test Acuuary 0.9802  Train Acuuary 0.9947636 Learning Rate 0.000291989\n",
      "Iter 25  Test Acuuary 0.9801  Train Acuuary 0.99487275 Learning Rate 0.00027738957\n",
      "Iter 26  Test Acuuary 0.9812  Train Acuuary 0.9951818 Learning Rate 0.0002635201\n",
      "Iter 27  Test Acuuary 0.981  Train Acuuary 0.99527276 Learning Rate 0.00025034408\n",
      "Iter 28  Test Acuuary 0.9803  Train Acuuary 0.9954364 Learning Rate 0.00023782688\n",
      "Iter 29  Test Acuuary 0.9809  Train Acuuary 0.9955091 Learning Rate 0.00022593554\n",
      "Iter 30  Test Acuuary 0.9822  Train Acuuary 0.9955091 Learning Rate 0.00021463877\n",
      "Iter 31  Test Acuuary 0.9813  Train Acuuary 0.9956545 Learning Rate 0.00020390682\n",
      "Iter 32  Test Acuuary 0.9814  Train Acuuary 0.99578184 Learning Rate 0.00019371149\n",
      "Iter 33  Test Acuuary 0.9807  Train Acuuary 0.9957455 Learning Rate 0.0001840259\n",
      "Iter 34  Test Acuuary 0.9807  Train Acuuary 0.9958182 Learning Rate 0.00017482461\n",
      "Iter 35  Test Acuuary 0.9818  Train Acuuary 0.99587274 Learning Rate 0.00016608338\n",
      "Iter 36  Test Acuuary 0.9817  Train Acuuary 0.9959273 Learning Rate 0.00015777921\n",
      "Iter 37  Test Acuuary 0.9815  Train Acuuary 0.9960182 Learning Rate 0.00014989026\n",
      "Iter 38  Test Acuuary 0.9807  Train Acuuary 0.99603635 Learning Rate 0.00014239574\n",
      "Iter 39  Test Acuuary 0.9818  Train Acuuary 0.99610907 Learning Rate 0.00013527596\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(40):\n",
    "        sess.run(tf.assign(lr, 0.001 * (0.95 ** epoch)))\n",
    "        for batch in range(n_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            sess.run(train, feed_dict={\n",
    "                x : batch_xs,\n",
    "                y : batch_ys,\n",
    "                keep_prob : 0.83\n",
    "            })\n",
    "            \n",
    "        learning_rate = sess.run(lr)\n",
    "        \n",
    "        test_acc = sess.run(accuary, feed_dict={\n",
    "            x:mnist.test.images,\n",
    "            y:mnist.test.labels,\n",
    "            keep_prob : 1.0\n",
    "        })\n",
    "        train_acc = sess.run(accuary, feed_dict={\n",
    "            x:mnist.train.images,\n",
    "            y:mnist.train.labels,\n",
    "            keep_prob : 1.0\n",
    "        })\n",
    "\n",
    "        print(\"Iter \" + str(epoch) + \"  Test Acuuary \" + str(test_acc) + \"  Train Acuuary \" + str(train_acc) + \" Learning Rate \" + str(learning_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
