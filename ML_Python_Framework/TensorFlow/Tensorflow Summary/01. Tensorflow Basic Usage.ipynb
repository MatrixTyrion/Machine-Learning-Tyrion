{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 张量可以被简单理解为多维数组\n",
    "+ 在张量中并没有真正保存数字，它保存的是如何得到这些数字的计算过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"add:0\", shape=(4, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant([[1,2,3],[1,2,3],[1,2,3],[1,2,3]], name='a')\n",
    "b = tf.constant([[3,4,5],[3,4,5],[3,4,5],[3,4,5]], name='b')\n",
    "\n",
    "result = tf.add(a,b, name='add')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(4), Dimension(3)])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.get_shape()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 一个张量中主要保存了三个属性\n",
    "    + 名字，name\n",
    "    + 纬度，shape\n",
    "    + 类型，type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Tensor(\"add:0\", shape=(4, 3), dtype=int32)`**\n",
    "+ 张量的第一个属性名字不仅是一个张量的唯一标识符，它同样给出了这个张量是如何计算出来的\n",
    "+ 张量和计算图上节点所代表的计算结果是对应的\n",
    "    + \"node : src_output\" 的形式\n",
    "    + src_output 表示当前张量来自节点的第几个输出\n",
    "\n",
    "    + type：每个张量都会有唯一类型\n",
    "    + 如果不指定类型，Tensorflow 会给出默认的类型\n",
    "        +比如不带小数点的数会被默认为 int32，带小数点的会默认为 float32\n",
    "\n",
    "+ **`张量的作用`**\n",
    "    + 对中间计算结果的引用，提高代码的可读性\n",
    "    + 通过张量来存储中间结果，方便获取中间结果\n",
    "    + **`Tensor.get_shape()`** 可以快速获取张量的纬度信息"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Tensor & Variable`**\n",
    "+ Tensorflow 的核心概念是 Tensor，所有的数据都是通过 Tensor 的形式来组织的\n",
    "+ Variable 的声明函数 tf.Variable() 只是一个运算\n",
    "+ 这个运算的输出结果就是一个张量\n",
    "+ **`变量只是一种特殊的张量`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constant & Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`tf.constant`**(value, dtype=None, shape=None, name='Const', verify_shape=False)\n",
    "+ tf.constant_initializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4]\n"
     ]
    }
   ],
   "source": [
    "cost = tf.constant([1,2,3,4])\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "bias = tf.constant(0.0, dtype=tf.float32, shape=[1,8])\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    print(sess.run(bias))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`tf.Variable`**(initial_value, trainable, collections, validate_shape, name, dtype)\n",
    "+ initial_value : A `Tensor`, or Python object convertible to a `Tensor`, which is the initial value for the Variable.\n",
    "+ trainable: \n",
    "    + If `True`, the default, also adds the variable to the graph collection `GraphKeys.TRAINABLE_VARIABLES`. \n",
    "    + This collection is used as the default list of variables to use by the `Optimizer` classes.\n",
    "+ collections: \n",
    "    + List of graph collections keys. \n",
    "    + The new variable is added to these collections. Defaults to `[GraphKeys.GLOBAL_VARIABLES]`.\n",
    "+ validate_shape: \n",
    "    + If `False`, allows the variable to be initialized with a value of unknown shape.\n",
    "    + If `True`, the default, the shape of `initial_value` must be known."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "zeros = tf.zeros([3,4])\n",
    "var = tf.Variable(zeros)\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    print(sess.run(var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.321705   -6.908461    0.25333065]\n",
      " [-2.4780028  -1.1168464   2.2765076 ]]\n"
     ]
    }
   ],
   "source": [
    "weights = tf.Variable(tf.random_normal([2,3], stddev=2))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    print(sess.run(weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variable & Placeholder & Fetch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Fetch`**\n",
    "+ 在一个绘画中可以`同时执行多个op`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mul, add] : [21.0, 7.0]\n"
     ]
    }
   ],
   "source": [
    "input1 = tf.constant(3.0)\n",
    "input2 = tf.constant(2.0)\n",
    "input3 = tf.constant(5.0)\n",
    "\n",
    "add = tf.add(input2, input3)\n",
    "mul = tf.multiply(input1, add)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    result = sess.run([mul, add])  # <<<　Fetch\n",
    "    print(\"[mul, add] :\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Feed`**\n",
    "+ **在运行时, 才传入相应的值**\n",
    "+ 占位符 : tf.placeholder(tf.float32)\n",
    "+ feed_dict = {.. value ..}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14.]\n"
     ]
    }
   ],
   "source": [
    "input1 = tf.placeholder(tf.float32)  # 创建 float32 类型的占位符\n",
    "input2 = tf.placeholder(tf.float32)\n",
    "\n",
    "output = tf.multiply(input1, input2)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    res = sess.run(output, feed_dict={\n",
    "        input1:[7.0],\n",
    "        input2:[2.]\n",
    "    })\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.1395674 1.2711904 1.6946031]]\n"
     ]
    }
   ],
   "source": [
    "w1 = tf.Variable(tf.random_normal([3,2], stddev=1))\n",
    "w2 = tf.Variable(tf.random_normal([1,3], stddev=1))\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=(2,3), name=\"input\")\n",
    "a = tf.matmul(w1, x)\n",
    "y = tf.matmul(w2, a)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    res = sess.run(y, feed_dict={\n",
    "        x : [[0.7,0.5,0.5],[0.9,0.4,0.8]]\n",
    "    })\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`tf.placeholder() & feed_dict=`**\n",
    "+ Tensorflow 提供了一个 placeholder 机制用于提供输入数据\n",
    "+ placeholder 相当于定义一个位置，这个位置中的数据在程序运行时再指定\n",
    "\n",
    "\n",
    "+ `tf.placeholder(tf.float32, shape=(2,3), name=\"input\")`\n",
    "    + 在 placeholder 定义时，这个位置上的数据类型是需要指定的，并不可以改变\n",
    "    + placeholder 中的数据纬度信息，可以根据提供的数据推导出来，所以不一定要给出\n",
    "    + 计算向前传播结果时，需要提供一个 feed_dict 来指定 x 的取值\n",
    "    + feed_dict 是一个字典，在字典中需要给出每个用到的 placeholder 的取值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get_variable & variable_scope(\"\", reuse= )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`tf.get_variable`**(name, shape=None, dtype=None, initializer=None, regularizer=None, trainable=None, collections=None)\n",
    "+ 初始化更方便\n",
    "```\n",
    "W = tf.get_variable(\"W\", shape=[784, 256], initializer=tf.contrib.layers.xavier_initializer())\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`tf.variable_scope`**(name_or_scope, reuse=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 当神经网络的结构更加复杂, 参数更多时, 就需要一个更好的方式来传递和管理神经网络中的参数\n",
    "+ Tensorflow 提供了`通过变量名称`来创建或者获取一个变量的机制\n",
    "+ 通过这个机制, 在不同的函数中可以直接通过变量的名字来使用变量, 而不需要将变量通过参数的形式到处传递"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ tf.get_variable() 用于创建变量时, 它和 tf.Variable() 的功能是基本等价的\n",
    "    + 对于 tf.Variable 函数, 变量名称是一个可选的参数\n",
    "    + 对于 tf.get_variable 函数, 变量名称是一个必选参数\n",
    "```\n",
    "    v = tf.get_variable(\"var_00\", shape=[1], initializer=tf.constant_initializer(1.0))\n",
    "    v = tf.Variable(tf.constant(1.0, shape=[1]), name='var_00')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`tf.get_variable 工作机制`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 当 `tf.get_variable_scope().reuse == False`，调用该函数会创建新的变量\n",
    "```\n",
    "      with tf.variable_scope(\"foo\"):\n",
    "          v = tf.get_variable(\"v\", [1])\n",
    "      assert v.name == \"foo/v:0\"\n",
    "```\n",
    "    　　\n",
    "\n",
    "+ 当 `tf.get_variable_scope().reuse == True`，调用该函数会重用已经创建的变量\n",
    "```\n",
    "      with tf.variable_scope(\"foo\"):\n",
    "          v = tf.get_variable(\"v\", [1])\n",
    "      with tf.variable_scope(\"foo\", reuse=True):\n",
    "          v1 = tf.get_variable(\"v\", [1])\n",
    "      assert v1 is v\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`tf.variable_scope 工作机制`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ `tf.variable_scope()`用来指定变量的作用域，作为变量名的前缀，支持嵌套\n",
    "```\n",
    "    with tf.variable_scope(\"foo\"):\n",
    "        with tf.variable_scope(\"bar\"):\n",
    "            v = tf.get_variable(\"v\", [1])\n",
    "    assert v.name == \"foo/bar/v:0\"\n",
    "```\n",
    "\n",
    "+ 当前环境的作用域可以通过函数 `tf.get_variable_scope()` 获取\n",
    "+ 并且 **`reuse flag`** 可以通过调用 `reuse_variables()` 设置为True\n",
    "```\n",
    "    with tf.variable_scope(\"foo\"):\n",
    "        v = tf.get_variable(\"v\", [1])\n",
    "        tf.get_variable_scope().reuse_variables()\n",
    "        v1 = tf.get_variable(\"v\", [1])\n",
    "    assert v1 is v\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Sharing variables`**\n",
    "+ 使用`tf.variable_scope()`来生成一个上下文管理器, 在这个上下文管理器中, 通过`tf.get_variable()`来`创建/获取`变量\n",
    "+ **`tf.variable_scope(., reuse=True)`** & **`tf.get_variable()`** 获取\n",
    "    + 获取 : 如果变量不存在, 则tf.get_variable()将报错\n",
    "    + 创建 : 如果同名的变量已经存在, 则tf.get_variable()函数将报错"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`reuse = tf.AUTO_REUSE`**\n",
    "+ 自动复用\n",
    "+ 如果变量存在则复用，不存在则创建\n",
    "+ 避免了代码的繁琐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "foo/v:0\n",
      "foo/v:0\n"
     ]
    }
   ],
   "source": [
    "def foo():\n",
    "    with tf.variable_scope(\"foo\", reuse=tf.AUTO_REUSE):\n",
    "        v = tf.get_variable(\"v\", [1], initializer=tf.ones_initializer)\n",
    "    return v\n",
    "\n",
    "v1 = foo()  # Creates v.\n",
    "v2 = foo()  # Gets the same, existing v.\n",
    "\n",
    "print(v1.name)\n",
    "print(v2.name)\n",
    "assert v1 == v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Example - 00`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tyrion/var_01:0\n",
      "[0.]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    with tf.variable_scope(\"Tyrion\"):\n",
    "        var = tf.get_variable('var_01', [1], initializer=tf.zeros_initializer)\n",
    "        print(var.name)\n",
    "\n",
    "    with tf.variable_scope(\"Tyrion\", reuse=True):\n",
    "        get_var = tf.get_variable(\"var_01\")\n",
    "        tf.global_variables_initializer().run()\n",
    "        print(sess.run(get_var))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Example - 01`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"foo\"):\n",
    "    with tf.variable_scope(\"bar\"):\n",
    "        v = tf.get_variable(\"var_02\", [1])\n",
    "        assert v.name == \"foo/bar/var_02:0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Example - 02`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_relu(input, kernel_shape, bias_shape):\n",
    "    weights = tf.get_variable(\"weights\", kernel_shape, initializer=tf.random_normal_initializer())\n",
    "    biases = tf.get_variable(\"biases\", bias_shape, initializer=tf.constant_initializer(0.0))\n",
    "    conv = tf.nn.conv2d(input, weights, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    return tf.nn.relu(conv + biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 需要两个卷积层，可以通过 tf.variable_scope() 指定作用域进行区分\n",
    "# 如 with tf.variable_scope(\"conv1\") 指定了第一个卷积层作用域为conv1\n",
    "# 在这个作用域下有两个变量 weights 和 biases\n",
    "\n",
    "def my_image_filter(input_images):\n",
    "    with tf.variable_scope(\"conv1\"):\n",
    "        # Variables created here will be named \"conv1/weights\", \"conv1/biases\".\n",
    "        relu1 = conv_relu(input_images, [5, 5, 32, 32], [32])\n",
    "    with tf.variable_scope(\"conv2\"):\n",
    "        # Variables created here will be named \"conv2/weights\", \"conv2/biases\".\n",
    "        return conv_relu(relu1, [5, 5, 32, 32], [32])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 在 image_filters 这个作用域, 重复使用第一张图片输入时创建的变量，调用函数reuse_variables()\n",
    "```\n",
    "with tf.variable_scope(\"image_filters\") as scope:\n",
    "    result1 = my_image_filter(image1)\n",
    "    scope.reuse_variables()\n",
    "    result2 = my_image_filter(image2)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Example - 03`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(in_put, in_channel, out_channel):\n",
    "    with tf.variable_scope(name_or_scope='', reuse=tf.AUTO_REUSE): ### 改动部分 ###\n",
    "        weights = tf.get_variable(name=\"weights\", shape=[2, 2, in_channel, out_channel], \n",
    "                                  initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "        convolution = tf.nn.conv2d(input=in_put, filter=weights, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "        return convolution\n",
    "\n",
    "def main():\n",
    "    with tf.Graph().as_default():\n",
    "        input_x = tf.placeholder(dtype=tf.float32, shape=[1, 4, 4, 1])\n",
    "        for _ in range(5):    # 重复调用\n",
    "            output = func(input_x, 1, 1)\n",
    "            with tf.Session() as sess:\n",
    "                sess.run(tf.global_variables_initializer())\n",
    "                _output = sess.run([output], feed_dict={\n",
    "                    input_x : np.random.uniform(low=0, high=255, size=[1, 4, 4, 1])\n",
    "                })\n",
    "                # print(_output)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **`Use already have value`**\n",
    "+ **`Fix Value`**\n",
    "+ **`Sequence`**\n",
    "+ **`Random Value`**\n",
    "+ **`initializer`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Tensor.initialized_value()`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.09402636  2.5565817  -1.3705839 ]\n",
      " [-0.3344355   1.6579056   1.5512991 ]]\n",
      "\n",
      "[[-0.18805273  5.1131635  -2.7411678 ]\n",
      " [-0.668871    3.3158112   3.1025982 ]]\n"
     ]
    }
   ],
   "source": [
    "weights = tf.Variable(tf.random_normal([2,3], stddev=2))\n",
    "\n",
    "weights_ = tf.Variable(weights.initialized_value() * 2.0)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    print(sess.run(weights))\n",
    "    print()\n",
    "    print(sess.run(weights_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Fix Value`**\n",
    "+ tf.`fill`(dims, value, name=None)\n",
    "+ tf.`zeros`(shape, dtype=tf.float32, name=None) / tf.`ones`( )\n",
    "+ tf.`zeros_like`(tensor, dtype=None, name=None, optimize=True) / tf.`ones_like`( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 1]\n",
      " [1 1 1 1]\n",
      " [1 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "f_one = tf.fill([3,4], 1)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(f_one))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "\n",
      "(3, 4)\n",
      "(4, 4)\n"
     ]
    }
   ],
   "source": [
    "ones = tf.ones([4,4])\n",
    "zeros = tf.zeros([3,4])\n",
    "zeros_l = tf.zeros_like(ones)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    print(sess.run(zeros))\n",
    "    print(sess.run(zeros_l))\n",
    "    print()\n",
    "    print(zeros.get_shape())\n",
    "    print(zeros_l.get_shape())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Sequence`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **`tf.linspace(start, stop, num, name=None)`**\n",
    "    + 在 [start,stop] 范围内产生 num 个数的等差数列\n",
    "    + start & stop 要用浮点数表示\n",
    "    \n",
    "+ **`tf.range(start, limit=None, delta=1, dtype=None, name='range')`**\n",
    "    + 在 [start,limit) 范围内以步进值 delta 产生等差数列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 2. 3. 4. 5.]\n",
      "[1 2 3 4]\n"
     ]
    }
   ],
   "source": [
    "x = tf.linspace(start=1.0, stop=5.0, num=5, name=None)\n",
    "y = tf.range(start=1,limit=5, delta=1)\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(x))\n",
    "    print(sess.run(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Random Value`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **`tf.random_normal(shape, mean=0.0, stddev=1.0, dtype=tf.float32, seed=None, name=None)`**\n",
    "    + Outputs random values from a normal distribution.\n",
    "    + 正态分布"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **`tf.truncated_normal(shape, mean=0.0, stddev=1.0, dtype=tf.float32, seed=None, name=None)`**\n",
    "    + Outputs random values from a truncated normal distribution.\n",
    "    + 截断正态分布，只保留 [mean-2*stddev, mean+2*stddev] 内的随机数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **`tf.random_uniform(shape, minval=0, maxval=None, dtype=tf.float32, seed=None, name=None)`**\n",
    "    + Outputs random values from a uniform distribution.\n",
    "    + 均匀分布 : [minval, maxval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`initializer`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ tf.ones_initializer(dtype=tf.float32)\n",
    "+ tf.zeros_initializer(dtype=tf.float32)\n",
    "+ tf.constant_initializer(value=0, dtype=tf.float32, verify_shape=False)\n",
    "+ tf.random_uniform_initializer(minval=0, maxval=None, seed=None, dtype=tf.float32)\n",
    "+ tf.random_normal_initializer(mean=0.0, stddev=1.0, seed=None, dtype=tf.float32)\n",
    "+ tf.truncated_normal_initializer(mean=0.0, stddev=1.0, seed=None, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph & Session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Tensorflow 中的每一个计算都是计算图上的一个节点，而节点之间的边描述了计算之间的依赖关系\n",
    "\n",
    "\n",
    "+ Tensorflow 程序中，系统会自动维护一个默认的计算图\n",
    "    + **`tf.get_default_graph()`**：获取当前默认的计算图\n",
    "    + **`Tensor.graph`**：查看张量所属的计算图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.constant(1)\n",
    "a.graph is tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **`tf.Graph()`**:生成新的计算图\n",
    "    + `with tf.Graph().as_default()`\n",
    "    + `with tf.Session(graph=…) as sess:`\n",
    "\n",
    "\n",
    "+ **`不同计算图上的 \"张量 & 运算\" 都不会共享`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.] in Graph-01\n",
      "[1.] in Graph-02\n"
     ]
    }
   ],
   "source": [
    "g1 = tf.Graph()\n",
    "with g1.as_default():\n",
    "    v = tf.get_variable('var_03', initializer=tf.zeros(shape=[1]))\n",
    "\n",
    "g2 = tf.Graph()\n",
    "with g2.as_default():\n",
    "    v = tf.get_variable('var_03', initializer=tf.ones(shape=[1]))\n",
    "\n",
    "with tf.Session(graph=g1) as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    with tf.variable_scope(\"\", reuse=True):\n",
    "        print(sess.run(tf.get_variable('var_03')), \"in Graph-01\")\n",
    "\n",
    "with tf.Session(graph=g2) as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    with tf.variable_scope(\"\", reuse=True):\n",
    "        print(sess.run(tf.get_variable('var_03')), \"in Graph-02\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Session / 会话`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ `会话拥有并管理 Tensorflow 程序运行时的所有资源`\n",
    "\n",
    "\n",
    "+ 当所有计算完成之后，需要关闭会话来帮助系统回收资源，否则就可能出现资源泄露的问题\n",
    "    + Method.01 : 明确调用会话生成和关闭函数\n",
    "    + Method.02 : 为了解决异常退出时，资源释放的问题\n",
    "        + Tensorflow 可以通过 Python 的上下文管理器来使用会话\n",
    "        + 当上下文管理器退出时，则会自动释放所有资源"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ tensorflow中的Tensor是保存了计算这个值的路径(方法)，当我们run的时候，tensorflow后端就通过路径计算出Tensor对应的值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Method-01`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "# sess.run(...)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Method-02`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 与 graph 不同的是, **`Tensorflow 不会自动生成默认的会话，而是需要手动指定`**\n",
    "    + `sess.as_default`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "[ True  True  True]\n",
      "[1 2 3]\n",
      "[1 2 3]\n"
     ]
    }
   ],
   "source": [
    "test = tf.constant([1,2,3], name='test')\n",
    "\n",
    "sess = tf.Session()\n",
    "with sess.as_default():\n",
    "    print(sess is tf.get_default_session())\n",
    "    \n",
    "    print(test.eval() == sess.run(test))\n",
    "    print(test.eval())\n",
    "    print(sess.run(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Tensor.eval() & tf.get_default_session().run(Tensor)`**\n",
    "+ **`sess.run() 可以一步获取多个tensor中的值`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([4, 6, 8]), array([ 3,  8, 15])]\n",
      "[4 6 8] [ 3  8 15]\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant([1, 2, 3], name='a')\n",
    "b = tf.constant([3, 4, 5], name='b')\n",
    "\n",
    "add = tf.add(a, b, name='add')\n",
    "mul = tf.multiply(a, b, name='mul')\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run([add, mul]))\n",
    "    print(add.eval(session=sess), mul.eval(session=sess))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.collection / 集合 / 整合资源"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 在一个计算图中，可以通过集合 collection 来管理不同类别的资源\n",
    "    + 资源类型：张量、变量\n",
    "+ collection 提供了一种 '零存整取' 的思路：\n",
    "    + 在任意位置，任意层次都可以创建对象，存入相应的 collection 中\n",
    "    + 创建完成后，统一从一个 collection 中取出一类变量，施加相应的操作\n",
    "    + collection 提供一个全局的存储机制，不会受到变量名生存空间的影响\n",
    "    \n",
    "+ 通过 `tf.add_to_collection()` 可以将资源加入一个或多个集合中\n",
    "+ 然后通过 `tf.get_collection()` 获取一个集合里面的所有资源"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`tf.GraphKeys`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ tf.GraphKeys.**GLOBAL_VARIABLES**\n",
    "    + 默认的 Variable 对象集合，在分布式环境共性\n",
    "    + 使用场景：持久化 Tensorflow 模型\n",
    "\n",
    "\n",
    "+ tf.GraphKeys.**LOCAL_VARIABLES**\n",
    "    + 每台计算机的局部变量\n",
    "    + 通常用于临时变量，如：计数器\n",
    "    + 使用 tf.contrib.framework.local_variable 添加到此集合\n",
    "\n",
    "\n",
    "+ tf.GraphKeys.**MODEL_VARIABLES**\n",
    "    + 在构建模型时，所有用于正向传播的 Variable 都将添加到这里\n",
    "    + 使用 tf.contrib.framework.model_variable 添加到此集合\n",
    "\n",
    "\n",
    "+ tf.GraphKeys.**TRAINABLE_VARIABLES**\n",
    "    + 将有优化器训练的变量\n",
    "    + tf.trainable_variables()\n",
    "\n",
    "\n",
    "+ tf.GraphKeys.**SUMMARIES**\n",
    "    + 日志生成相关的张量\n",
    "    + Tensorflow 计算可视化\n",
    "\n",
    "\n",
    "+ tf.GraphKeys.**MOVING_AVERAGE_VARIABLES**\n",
    "    + 所有计算了滑动平均值的变量\n",
    "    + tf.moving_average_variables\n",
    "\n",
    "\n",
    "+ tf.GraphKeys.**REGULARIZATION_LOSSES**\n",
    "    + 收集在图构造期间正则化损失"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`tf.add_to_collection(name, value)`**\n",
    "+ name: The key for the collection. The GraphKeys class contains many standard names for collections.\n",
    "+ value: The value to add to the collection.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`tf.get_collection(key, scope=None)`**\n",
    "+ key: The key for the collection. For example, the GraphKeys class contains many standard names for collections.\n",
    "+ return:\n",
    "    + `The list of values` in the collection with the given `name`, or an empty list if no value has been added to that collection.\n",
    "    + The list contains the values in the order under which they were collected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tf.get_collection() 按照添加时的'顺序 & 结构'获取'集合元素'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"a_2:0\", shape=(2,), dtype=int32)\n",
      "Tensor(\"b_2:0\", shape=(1,), dtype=int32)\n",
      "[<tf.Tensor 'a_2:0' shape=(2,) dtype=int32>, <tf.Tensor 'b_2:0' shape=(1,) dtype=int32>]\n",
      "---------\n",
      "a_2:0 [1 2]\n",
      "b_2:0 [3]\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant([1,2], name='a')\n",
    "b = tf.constant([3], name='b')\n",
    "tf.add_to_collection('Test', a)\n",
    "tf.add_to_collection('Test', b)\n",
    "tf.add_to_collection('Test', [a,b])\n",
    "\n",
    "vars = tf.get_collection('Test')\n",
    "for var in vars:\n",
    "    print(var)\n",
    "print('---------')\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    for var in vars:\n",
    "        if not isinstance(var, list):\n",
    "            print(var.name, sess.run(var))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tf.get_variable & tf.get_colletion`\n",
    "+ tf.get_variable() 中 `collections=None` 等价于 `collection=[tf.GraphKeys.GLOBAL_VARIABLES]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable:0 \n",
      " [[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "Variable_1:0 \n",
      " [[ 0.9180692  -3.3838112   2.71286   ]\n",
      " [ 0.55919445 -1.089166    2.980913  ]]\n",
      "Variable_2:0 \n",
      " [[0.00853385 1.6481047 ]\n",
      " [1.0352571  0.94730854]\n",
      " [0.6027661  0.51231086]]\n",
      "Variable_3:0 \n",
      " [[-1.1362771 -0.8955608 -0.6792621]]\n",
      "foo/v:0 \n",
      " [1.]\n",
      "Tyrion/var_01:0 \n",
      " [0.]\n",
      "foo/bar/var_02:0 \n",
      " [-1.3179361]\n",
      "Variable_4:0 \n",
      " [[-1.7656925   0.20996203 -1.1696948 ]\n",
      " [ 0.2881413   0.06542689 -5.168431  ]]\n",
      "Variable_5:0 \n",
      " [[ -3.531385     0.41992405  -2.3393896 ]\n",
      " [  0.5762826    0.13085377 -10.336862  ]]\n",
      "a_01:0 \n",
      " [[ 1.093994    0.953705  ]\n",
      " [ 1.4361348  -1.1914153 ]\n",
      " [-0.57483804  1.1861914 ]]\n",
      "a_02:0 \n",
      " [ 0.47713545 -0.03824668 -1.4490979   0.50916195 -0.85737807 -0.54701686\n",
      "  0.42262328 -1.032796    1.7862451   1.9440341 ]\n"
     ]
    }
   ],
   "source": [
    "a = tf.get_variable(\"a_01\", [3,2], initializer=tf.random_normal_initializer())\n",
    "b = tf.get_variable(\"a_02\", [10], initializer=tf.random_normal_initializer())\n",
    "\n",
    "gloable_variables = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    for var in gloable_variables:\n",
    "        print(var.name, '\\n', sess.run(var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b_01:0 \n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "b_02:0 \n",
      " [[1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "a = tf.get_variable(name=\"b_01\", shape=[10], initializer=tf.zeros_initializer)\n",
    "b = tf.get_variable(name=\"b_02\", shape=[3,4], initializer=tf.ones_initializer())\n",
    "tf.add_to_collection('Tyrion', a)\n",
    "tf.add_to_collection('Tyrion', b)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    keys = tf.get_collection(\"Tyrion\")\n",
    "    for key in keys:\n",
    "        print(key.name, '\\n', sess.run(key))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ `如果使用 get_variable 的 collections 参数，在变量声明时，就将其加入到 collection 中`\n",
    "+ `获取其值时，需要通过 feed_dict`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c_01:0 \t [1.]\n",
      "c_02:0 \t [1.]\n"
     ]
    }
   ],
   "source": [
    "a = tf.get_variable(name=\"c_01\", shape=[1], collections=['C'])\n",
    "b = tf.get_variable(name=\"c_02\", shape=[1], collections=['C'])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    keys = tf.get_collection(\"C\")\n",
    "    for key in keys:\n",
    "        print(key.name, '\\t', sess.run(key, feed_dict={key : [1]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`tf.add_n(inputs, name=None)`**\n",
    "\n",
    "Adds all input tensors element-wise.\n",
    "+ inputs: A list of `Tensor` or `IndexedSlices` objects, each with same shape and type.\n",
    "+ name: A name for the operation (optional).\n",
    "+ Returns:\n",
    "    + A `Tensor` of same shape and type as the elements of `inputs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Variable 'd_1:0' shape=(1,) dtype=float32_ref>, <tf.Variable 'd_2:0' shape=(1,) dtype=float32_ref>]\n",
      "[2.]\n"
     ]
    }
   ],
   "source": [
    "v1 = tf.get_variable(name='d_1', shape=[1], initializer=tf.constant_initializer(0))\n",
    "v2 = tf.get_variable(name='d_2', shape=[1], initializer=tf.constant_initializer(2))\n",
    "\n",
    "tf.add_to_collection('D', v1)\n",
    "tf.add_to_collection('D', v2)\n",
    " \n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    print(tf.get_collection('D'))\n",
    "    print(sess.run(tf.add_n(tf.get_collection('D'))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`colletion & regularization`**\n",
    "+ `正则化`并不前向传播，只是在计算损失的时候使用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`add to colletion`\n",
    "```python\n",
    "l2_reg = tf.contrib.layers.l2_regularizer(scale=0.001)\n",
    "\n",
    "w = tf.get_variable('weight_1', [10, 20], dtype=tf.float32,\n",
    "                    initializer=tf.contrib.layers.xavier_initializer())\n",
    "tf.add_to_collection('regularizer_1', l2_reg(w))\n",
    "conv = tf.nn.conv2d(input, w, [1,stride,stride,1], padding='SAME')\n",
    "\n",
    "# bias 使用 tf.constant 来定义，难道不用优化吗？\n",
    "b = tf.get_variable('bias', [out_dim], dtype=tf.float32,\n",
    "                    initializer=tf.constant_initializer(0.))\n",
    "tf.add_to_collection('regularizer_1', l2_reg(b))\n",
    "\n",
    "out = tf.nn.bias_add(conv, b)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`calc loss`\n",
    "```python\n",
    "regular = tf.add_n(tf.get_collection('regularizer_1'), 'loss')\n",
    "\n",
    "with tf.variable_scope(name='loss') as scope:\n",
    "    loss = -tf.reduce_sum(label * tf.log(predict)) + regular\n",
    "    # cross entropy + l2_reg\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tf.get_variable() & tf.variable_scope()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ `tf.get_variable() & tf.variable_scope()` 这两个都有 `regularizer` 形参\n",
    "+ 如果传入这个参数的话，那么 variable_scope 中的 weights 的正则化损失就会被添加到 `GraphKeys.REGULARIZATION_LOSSES` 中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "regular = tf.contrib.layers.l1_regularizer(0.1)\n",
    "\n",
    "with tf.variable_scope('var_1',\n",
    "                       initializer=tf.random_normal_initializer(),\n",
    "                       regularizer=regular):\n",
    "    weight_1 = tf.get_variable('weight_01', shape=[8], initializer=tf.ones_initializer())\n",
    "\n",
    "with tf.variable_scope('var_2',\n",
    "                       initializer=tf.random_normal_initializer(),\n",
    "                       regularizer=regular):\n",
    "    weight_2 = tf.get_variable(\"weight_02\", shape=[8], initializer=tf.ones_initializer())\n",
    "\n",
    "regularization_loss = tf.reduce_sum(tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tf.contrib.layers.l2_regularizer()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "truediv:0 : 0.7\n"
     ]
    }
   ],
   "source": [
    "Tyrion = tf.Graph()\n",
    "with Tyrion.as_default():\n",
    "    weight_decay = 0.1\n",
    "    init = tf.constant([0,1,2,3],dtype=tf.float32)\n",
    "\n",
    "    \"\"\"\n",
    "    l2_reg = tf.contrib.layers.l2_regularizer(weight_decay)\n",
    "    a = tf.get_variable(\"a_001\",regularizer=l2_reg, initializer=init) \n",
    "    \"\"\"\n",
    "    # **上面代码的等价代码\n",
    "    a  = tf.get_variable(\"a_001\",initializer=init)\n",
    "    a2 = tf.reduce_sum(a * a) * weight_decay / 2\n",
    "    a3 = tf.get_variable(a.name.split(\":\")[0]+\"/Regularizer/l2_regularizer\", initializer=a2)\n",
    "    tf.add_to_collection(tf.GraphKeys.REGULARIZATION_LOSSES, a2)\n",
    "    # **\n",
    "\n",
    "with tf.Session(graph=Tyrion) as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    keys = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\n",
    "    for key in keys:\n",
    "        print(\"%s : %s\" %(key.name,sess.run(key)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Set:\n",
      "b_001:0\n",
      "--------------------\n",
      "Regular Set:\n",
      "b_001/Regularizer/l2_regularizer:0\n",
      "--------------------\n",
      "[0. 1. 2. 3.]\n",
      "l2_loss=0.7\n"
     ]
    }
   ],
   "source": [
    "Jean = tf.Graph()\n",
    "with Jean.as_default():\n",
    "    weight_decay = 0.1\n",
    "    init = tf.constant([0,1,2,3],dtype=tf.float32)\n",
    "\n",
    "    l2_reg = tf.contrib.layers.l2_regularizer(weight_decay)\n",
    "    tmp=tf.constant([0,1,2,3],dtype=tf.float32)\n",
    "    a = tf.get_variable(\"b_001\", regularizer=l2_reg, initializer=init)\n",
    "    \n",
    "with tf.Session(graph=Jean) as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    \n",
    "    print(\"Global Set:\")\n",
    "    keys = tf.get_collection(\"variables\")\n",
    "    for key in keys:\n",
    "        print(key.name)\n",
    "    print(\"--------------------\")  \n",
    "    \n",
    "    print(\"Regular Set:\")\n",
    "    keys = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\n",
    "    for key in keys:\n",
    "        print(key.name)\n",
    "    print(\"--------------------\")\n",
    "    \n",
    "    print(sess.run(a))\n",
    "    reg_set = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\n",
    "    l2_loss = tf.add_n(reg_set)\n",
    "    print(\"l2_loss=%s\" %(sess.run(l2_loss)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# operation / op"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Property`**\n",
    "+ `Tensor.get_shape()`\n",
    "+ `tf.shape(tensor)` || sess.run()\n",
    "+ `tf.reshape(tensor, shape, name=None)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 4)\n"
     ]
    }
   ],
   "source": [
    "tensor = tf.Variable(tf.ones([3,4], dtype=tf.float32))\n",
    "print(tensor.get_shape())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tf.shape() 函数本身也是返回一个张量，因而，需要用 sess.run() 来得到具体的值`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 4]\n"
     ]
    }
   ],
   "source": [
    "tensor = tf.Variable(tf.ones([3,4], dtype=tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(tf.shape(tensor)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 1)\n"
     ]
    }
   ],
   "source": [
    "tensor = tf.Variable(tf.ones([3,4], dtype=tf.float32))\n",
    "temp = tf.reshape(tensor, [-1,1])\n",
    "print(temp.get_shape())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Basic Math Method`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`tf.one_hot(indices, depth, dtype=None, name=None)`**\n",
    "\n",
    "Returns a one-hot tensor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "indices = [0, 1, 2]\n",
    "depth = 3\n",
    "tf.one_hot(indices, depth)  # output: [3 x 3]\n",
    "# [[1., 0., 0.],\n",
    "#  [0., 1., 0.],\n",
    "#  [0., 0., 1.]]\n",
    "\n",
    "indices = [0, 2, -1, 1]\n",
    "depth = 3\n",
    "tf.one_hot(indices, depth,\n",
    "           on_value=5.0, off_value=0.0,\n",
    "           axis=-1)  # output: [4 x 3]\n",
    "# [[5.0, 0.0, 0.0],  # one_hot(0)\n",
    "#  [0.0, 0.0, 5.0],  # one_hot(2)\n",
    "#  [0.0, 0.0, 0.0],  # one_hot(-1)\n",
    "#  [0.0, 5.0, 0.0]]  # one_hot(1)\n",
    "\n",
    "indices = [[0, 2], [1, -1]]\n",
    "depth = 3\n",
    "tf.one_hot(indices, depth,\n",
    "           on_value=1.0, off_value=0.0,\n",
    "           axis=-1)  # output: [2 x 2 x 3]\n",
    "# [[[1.0, 0.0, 0.0],   # one_hot(0)\n",
    "#   [0.0, 0.0, 1.0]],  # one_hot(2)\n",
    "#  [[0.0, 1.0, 0.0],   # one_hot(1)\n",
    "#   [0.0, 0.0, 0.0]]]  # one_hot(-1)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`tf.assign(ref, value)`**\n",
    "\n",
    "Update 'ref' by assigning 'value' to it.\n",
    "\n",
    "+ ref: A mutable `Tensor`. Should be from a `Variable` node. May be uninitialized.\n",
    "+ value: A `Tensor`. Must have the same type as `ref`. The value to be assigned to the variable.\n",
    "\n",
    "+ Returns:\n",
    "    + A `Tensor` that will hold the new value of 'ref' after the assignment has completed.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "count = tf.Variable(0, name='counter')\n",
    "one = tf.constant(1)\n",
    "new_value = tf.add(count, one)\n",
    "\n",
    "update = tf.assign(count, new_value)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    print(sess.run(count))\n",
    "    for _ in range(5):\n",
    "        sess.run(update)\n",
    "        print(sess.run(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.pow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.multiply\n",
    "tf.mul\n",
    "實現兩個矩陣點乘，兩個矩陣必須要相同維度\n",
    "\n",
    "tf.matmul\n",
    "將a,b兩個矩陣相乘，如果需要事先轉置的話，可以把個別的選項調成True，如果矩陣裏面包括很多0的話，可以調用spare=True轉為更有效率的演算法\n",
    "\n",
    "对应元素相乘 *\n",
    "矩阵乘法 tf.matmul\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "自定义损失函数\n",
    "loss = tf.reduce_sum(tf.where(tf.greater(v1,v2), (v1-v2) * a, (v2-v1) * b))\n",
    "\n",
    "v1 = tf.constant([1., 2., 3., 4.])\n",
    "v2 = tf.constant([4., 3., 2., 1.])\n",
    "compare = tf.greater(v1, v2)\n",
    "which = tf.where(compare, v1, v2)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(compare))\n",
    "    print(sess.run(which))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Statistics Method`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`calc on some axis`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "tf.reduce_max(input_tensor, axis=None, keepdims=None)\n",
    "tf.reduce_min(input_tensor, axis=None, keepdims=None)\n",
    "tf.reduce_sum(input_tensor, axis=None, keepdims=None)\n",
    "tf.reduce_mean(input_tensor, axis=None, keepdims=None)\n",
    "\n",
    "tf.reduce_prod(input_tensor, axis=None, keepdims=None) # 连乘\n",
    "    # Computes the product of elements across dimensions of a tensor. (deprecated arguments)\n",
    "tf.reduce_all(input_tensor, axis=None, keepdims=None)\n",
    "    # Computes the \"logical and\" of elements across dimensions of a tensor. (deprecated arguments)\n",
    "tf.reduce_any(input_tensor, axis=None, keepdims=None)\n",
    "    # Computes the \"logical or\" of elements across dimensions of a tensor. (deprecated arguments)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ `input_tensor`: The boolean tensor to reduce.\n",
    "+ `axis`: The dimensions to reduce. If None (the default), reduces all dimensions.\n",
    "+ `keepdims`: If true, retains reduced dimensions with length 1. 如果为 False，执行后则会减少一个维度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "x = tf.constant([[1., 1., 1.], [2., 2., 2.]])\n",
    "tf.reduce_mean(x)  # 1.5\n",
    "tf.reduce_mean(x, 0)  # [1.5, 1.5, 1.5]\n",
    "tf.reduce_mean(x, 1)  # [1., 2.]\n",
    "tf.reduce_mean(x, 1, keepdims=True)  # [[1.], [2.]] / (2, 1)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "x = tf.constant([[1, 1, 1], [1, 1, 1]])\n",
    "tf.reduce_sum(x)  # 6\n",
    "tf.reduce_sum(x, 0)  # [2, 2, 2]\n",
    "tf.reduce_sum(x, 1)  # [3, 3]\n",
    "tf.reduce_sum(x, 1, keepdims=True)  # [[3], [3]]  tf.reduce_sum(x, 1, keepdims=True).get_shape()\n",
    "tf.reduce_sum(x, [0, 1])  # 6\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "a = tf.constant([[1,2,3], [4,5,6]])\n",
    "b = tf.reduce_prod(a) 720\n",
    "b_1 = tf.reduce_prod(a, axis=0) [4, 10, 18]\n",
    "b_2 = tf.reduce_prod(a, axis=1) [6, 120]\n",
    "b_3 = tf.reduce_prod(a, axis=0, keep_dims=True) [[4, 10, 18]]\n",
    "b_4 = tf.reduce_prod(a, axis=1, keep_dims=True) [[6],[120]]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`clip data / 裁剪数据`**\n",
    "+ `tf.clip_by_average_norm(t, clip_norm, name=None)`\n",
    "+ `tf.clip_by_global_norm(t_list, clip_norm, use_norm=None, name=None)`\n",
    "+ `tf.clip_by_norm(t, clip_norm, axes=None, name=None)`\n",
    "+ `tf.clip_by_value(t, clip_value_min, clip_value_max, name=None)`\n",
    "    + Clips tensor values to a specified min and max."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 2. 4.]\n",
      " [4. 5. 6.]]\n",
      "[[2.5 2.5 4. ]\n",
      " [4.  4.5 4.5]]\n"
     ]
    }
   ],
   "source": [
    "v = tf.constant([[1.0, 2.0, 4.0],[4.0, 5.0, 6.0]])\n",
    "result = tf.clip_by_value(v, 2.5, 4.5)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(v))\n",
    "    print(sess.run(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Assemble / Split data`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`tf.concat(values, axis, name='concat')`**\n",
    "+ Concatenates tensors along one dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  2  3]\n",
      " [ 4  5  6]\n",
      " [ 7  8  9]\n",
      " [10 11 12]]\n",
      "\n",
      "[[ 1  2  3  7  8  9]\n",
      " [ 4  5  6 10 11 12]]\n"
     ]
    }
   ],
   "source": [
    "t1 = [[1, 2, 3], [4, 5, 6]]\n",
    "t2 = [[7, 8, 9], [10, 11, 12]]\n",
    "\n",
    "t3 = tf.concat([t1, t2], 0)\n",
    "t4 = tf.concat([t1, t2], 1)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(t3))\n",
    "    print()\n",
    "    print(sess.run(t4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
