{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 张量可以被简单理解为多维数组\n",
    "+ 在张量中并没有真正保存数字，它保存的是如何得到这些数字的计算过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"add:0\", shape=(4, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant([[1,2,3],[1,2,3],[1,2,3],[1,2,3]], name='a')\n",
    "b = tf.constant([[3,4,5],[3,4,5],[3,4,5],[3,4,5]], name='b')\n",
    "\n",
    "result = tf.add(a,b, name='add')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(4), Dimension(3)])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.get_shape()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 一个张量中主要保存了三个属性\n",
    "    + 名字，name\n",
    "    + 纬度，shape\n",
    "    + 类型，type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Tensor(\"add:0\", shape=(4, 3), dtype=int32)`**\n",
    "+ 张量的第一个属性名字不仅是一个张量的唯一标识符，它同样给出了这个张量是如何计算出来的\n",
    "+ 张量和计算图上节点所代表的计算结果是对应的\n",
    "    + \"node : src_output\" 的形式\n",
    "    + src_output 表示当前张量来自节点的第几个输出\n",
    "\n",
    "    + type：每个张量都会有唯一类型\n",
    "    + 如果不指定类型，Tensorflow 会给出默认的类型\n",
    "        +比如不带小数点的数会被默认为 int32，带小数点的会默认为 float32\n",
    "\n",
    "+ **`张量的作用`**\n",
    "    + 对中间计算结果的引用，提高代码的可读性\n",
    "    + 通过张量来存储中间结果，方便获取中间结果\n",
    "    + **`Tensor.get_shape()`** 可以快速获取张量的纬度信息"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Tensor & Variable`**\n",
    "+ Tensorflow 的核心概念是 Tensor，所有的数据都是通过 Tensor 的形式来组织的\n",
    "+ Variable 的声明函数 tf.Variable() 只是一个运算\n",
    "+ 这个运算的输出结果就是一个张量\n",
    "+ **`变量只是一种特殊的张量`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constant & Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`tf.constant`**(value, dtype=None, shape=None, name='Const', verify_shape=False)\n",
    "+ tf.constant_initializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4]\n"
     ]
    }
   ],
   "source": [
    "cost = tf.constant([1,2,3,4])\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "bias = tf.constant(0.0, dtype=tf.float32, shape=[1,8])\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    print(sess.run(bias))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`tf.Variable`**(initial_value, trainable, collections, validate_shape, name, dtype)\n",
    "+ initial_value : A `Tensor`, or Python object convertible to a `Tensor`, which is the initial value for the Variable.\n",
    "+ trainable: \n",
    "    + If `True`, the default, also adds the variable to the graph collection `GraphKeys.TRAINABLE_VARIABLES`. \n",
    "    + This collection is used as the default list of variables to use by the `Optimizer` classes.\n",
    "+ collections: \n",
    "    + List of graph collections keys. \n",
    "    + The new variable is added to these collections. Defaults to `[GraphKeys.GLOBAL_VARIABLES]`.\n",
    "+ validate_shape: \n",
    "    + If `False`, allows the variable to be initialized with a value of unknown shape.\n",
    "    + If `True`, the default, the shape of `initial_value` must be known."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "zeros = tf.zeros([3,4])\n",
    "var = tf.Variable(zeros)\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    print(sess.run(var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.262013   -2.954741   -0.5825089 ]\n",
      " [ 4.5530753  -1.4434229  -0.81389755]]\n"
     ]
    }
   ],
   "source": [
    "weights = tf.Variable(tf.random_normal([2,3], stddev=2))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    print(sess.run(weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variable & Placeholder & Fetch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Fetch`**\n",
    "+ 在一个绘画中可以`同时执行多个op`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mul, add] : [21.0, 7.0]\n"
     ]
    }
   ],
   "source": [
    "input1 = tf.constant(3.0)\n",
    "input2 = tf.constant(2.0)\n",
    "input3 = tf.constant(5.0)\n",
    "\n",
    "add = tf.add(input2, input3)\n",
    "mul = tf.multiply(input1, add)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    result = sess.run([mul, add])  # <<<　Fetch\n",
    "    print(\"[mul, add] :\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Feed`**\n",
    "+ **在运行时, 才传入相应的值**\n",
    "+ 占位符 : tf.placeholder(tf.float32)\n",
    "+ feed_dict = {.. value ..}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14.]\n"
     ]
    }
   ],
   "source": [
    "input1 = tf.placeholder(tf.float32)  # 创建 float32 类型的占位符\n",
    "input2 = tf.placeholder(tf.float32)\n",
    "\n",
    "output = tf.multiply(input1, input2)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    res = sess.run(output, feed_dict={\n",
    "        input1:[7.0],\n",
    "        input2:[2.]\n",
    "    })\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.8403914  -0.45584244 -0.69373864]]\n"
     ]
    }
   ],
   "source": [
    "w1 = tf.Variable(tf.random_normal([3,2], stddev=1))\n",
    "w2 = tf.Variable(tf.random_normal([1,3], stddev=1))\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=(2,3), name=\"input\")\n",
    "a = tf.matmul(w1, x)\n",
    "y = tf.matmul(w2, a)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    res = sess.run(y, feed_dict={\n",
    "        x : [[0.7,0.5,0.5],[0.9,0.4,0.8]]\n",
    "    })\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`tf.placeholder() & feed_dict=`**\n",
    "+ Tensorflow 提供了一个 placeholder 机制用于提供输入数据\n",
    "+ placeholder 相当于定义一个位置，这个位置中的数据在程序运行时再指定\n",
    "\n",
    "\n",
    "+ `tf.placeholder(tf.float32, shape=(2,3), name=\"input\")`\n",
    "    + 在 placeholder 定义时，这个位置上的数据类型是需要指定的，并不可以改变\n",
    "    + placeholder 中的数据纬度信息，可以根据提供的数据推导出来，所以不一定要给出\n",
    "    + 计算向前传播结果时，需要提供一个 feed_dict 来指定 x 的取值\n",
    "    + feed_dict 是一个字典，在字典中需要给出每个用到的 placeholder 的取值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get_variable & variable_scope(\"\", reuse= )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`tf.get_variable`**(name, shape=None, dtype=None, initializer=None, regularizer=None, trainable=None, collections=None)\n",
    "+ 初始化更方便\n",
    "```\n",
    "W = tf.get_variable(\"W\", shape=[784, 256], initializer=tf.contrib.layers.xavier_initializer())\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`tf.variable_scope`**(name_or_scope, reuse=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 当神经网络的结构更加复杂, 参数更多时, 就需要一个更好的方式来传递和管理神经网络中的参数\n",
    "+ Tensorflow 提供了`通过变量名称`来创建或者获取一个变量的机制\n",
    "+ 通过这个机制, 在不同的函数中可以直接通过变量的名字来使用变量, 而不需要将变量通过参数的形式到处传递"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ tf.get_variable() 用于创建变量时, 它和 tf.Variable() 的功能是基本等价的\n",
    "    + 对于 tf.Variable 函数, 变量名称是一个可选的参数\n",
    "    + 对于 tf.get_variable 函数, 变量名称是一个必选参数\n",
    "```\n",
    "    v = tf.get_variable(\"var_00\", shape=[1], initializer=tf.constant_initializer(1.0))\n",
    "    v = tf.Variable(tf.constant(1.0, shape=[1]), name='var_00')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`tf.get_variable 工作机制`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 当 `tf.get_variable_scope().reuse == False`，调用该函数会创建新的变量\n",
    "```\n",
    "      with tf.variable_scope(\"foo\"):\n",
    "          v = tf.get_variable(\"v\", [1])\n",
    "      assert v.name == \"foo/v:0\"\n",
    "```\n",
    "    　　\n",
    "\n",
    "+ 当 `tf.get_variable_scope().reuse == True`，调用该函数会重用已经创建的变量\n",
    "```\n",
    "      with tf.variable_scope(\"foo\"):\n",
    "          v = tf.get_variable(\"v\", [1])\n",
    "      with tf.variable_scope(\"foo\", reuse=True):\n",
    "          v1 = tf.get_variable(\"v\", [1])\n",
    "      assert v1 is v\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`tf.variable_scope 工作机制`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ `tf.variable_scope()`用来指定变量的作用域，作为变量名的前缀，支持嵌套\n",
    "```\n",
    "    with tf.variable_scope(\"foo\"):\n",
    "        with tf.variable_scope(\"bar\"):\n",
    "            v = tf.get_variable(\"v\", [1])\n",
    "    assert v.name == \"foo/bar/v:0\"\n",
    "```\n",
    "\n",
    "+ 当前环境的作用域可以通过函数 `tf.get_variable_scope()` 获取\n",
    "+ 并且 **`reuse flag`** 可以通过调用 `reuse_variables()` 设置为True\n",
    "```\n",
    "    with tf.variable_scope(\"foo\"):\n",
    "        v = tf.get_variable(\"v\", [1])\n",
    "        tf.get_variable_scope().reuse_variables()\n",
    "        v1 = tf.get_variable(\"v\", [1])\n",
    "    assert v1 is v\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Sharing variables`**\n",
    "+ 使用`tf.variable_scope()`来生成一个上下文管理器, 在这个上下文管理器中, 通过`tf.get_variable()`来`创建/获取`变量\n",
    "+ **`tf.variable_scope(., reuse=True)`** & **`tf.get_variable()`** 获取\n",
    "    + 获取 : 如果变量不存在, 则tf.get_variable()将报错\n",
    "    + 创建 : 如果同名的变量已经存在, 则tf.get_variable()函数将报错"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`reuse = tf.AUTO_REUSE`**\n",
    "+ 自动复用\n",
    "+ 如果变量存在则复用，不存在则创建\n",
    "+ 避免了代码的繁琐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "foo/v:0\n",
      "foo/v:0\n"
     ]
    }
   ],
   "source": [
    "def foo():\n",
    "    with tf.variable_scope(\"foo\", reuse=tf.AUTO_REUSE):\n",
    "        v = tf.get_variable(\"v\", [1], initializer=tf.ones_initializer)\n",
    "    return v\n",
    "\n",
    "v1 = foo()  # Creates v.\n",
    "v2 = foo()  # Gets the same, existing v.\n",
    "\n",
    "print(v1.name)\n",
    "print(v2.name)\n",
    "assert v1 == v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Example - 00`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tyrion/var_01:0\n",
      "[0.]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    with tf.variable_scope(\"Tyrion\"):\n",
    "        var = tf.get_variable('var_01', [1], initializer=tf.zeros_initializer)\n",
    "        print(var.name)\n",
    "\n",
    "    with tf.variable_scope(\"Tyrion\", reuse=True):\n",
    "        get_var = tf.get_variable(\"var_01\")\n",
    "        tf.global_variables_initializer().run()\n",
    "        print(sess.run(get_var))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Example - 01`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"foo\"):\n",
    "    with tf.variable_scope(\"bar\"):\n",
    "        v = tf.get_variable(\"var_02\", [1])\n",
    "        assert v.name == \"foo/bar/var_02:0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Example - 02`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_relu(input, kernel_shape, bias_shape):\n",
    "    weights = tf.get_variable(\"weights\", kernel_shape, initializer=tf.random_normal_initializer())\n",
    "    biases = tf.get_variable(\"biases\", bias_shape, initializer=tf.constant_initializer(0.0))\n",
    "    conv = tf.nn.conv2d(input, weights, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    return tf.nn.relu(conv + biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 需要两个卷积层，可以通过 tf.variable_scope() 指定作用域进行区分\n",
    "# 如 with tf.variable_scope(\"conv1\") 指定了第一个卷积层作用域为conv1\n",
    "# 在这个作用域下有两个变量 weights 和 biases\n",
    "\n",
    "def my_image_filter(input_images):\n",
    "    with tf.variable_scope(\"conv1\"):\n",
    "        # Variables created here will be named \"conv1/weights\", \"conv1/biases\".\n",
    "        relu1 = conv_relu(input_images, [5, 5, 32, 32], [32])\n",
    "    with tf.variable_scope(\"conv2\"):\n",
    "        # Variables created here will be named \"conv2/weights\", \"conv2/biases\".\n",
    "        return conv_relu(relu1, [5, 5, 32, 32], [32])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 在 image_filters 这个作用域, 重复使用第一张图片输入时创建的变量，调用函数reuse_variables()\n",
    "```\n",
    "with tf.variable_scope(\"image_filters\") as scope:\n",
    "    result1 = my_image_filter(image1)\n",
    "    scope.reuse_variables()\n",
    "    result2 = my_image_filter(image2)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Example - 03`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(in_put, in_channel, out_channel):\n",
    "    with tf.variable_scope(name_or_scope='', reuse=tf.AUTO_REUSE): ### 改动部分 ###\n",
    "        weights = tf.get_variable(name=\"weights\", shape=[2, 2, in_channel, out_channel], \n",
    "                                  initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "        convolution = tf.nn.conv2d(input=in_put, filter=weights, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "        return convolution\n",
    "\n",
    "def main():\n",
    "    with tf.Graph().as_default():\n",
    "        input_x = tf.placeholder(dtype=tf.float32, shape=[1, 4, 4, 1])\n",
    "        for _ in range(5):    # 重复调用\n",
    "            output = func(input_x, 1, 1)\n",
    "            with tf.Session() as sess:\n",
    "                sess.run(tf.global_variables_initializer())\n",
    "                _output = sess.run([output], feed_dict={\n",
    "                    input_x : np.random.uniform(low=0, high=255, size=[1, 4, 4, 1])\n",
    "                })\n",
    "                # print(_output)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **`Use already have value`**\n",
    "+ **`Fix Value`**\n",
    "+ **`Sequence`**\n",
    "+ **`Random Value`**\n",
    "+ **`initializer`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Tensor.initialized_value()`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.2913926 -0.9373361  2.606292 ]\n",
      " [-1.7561935 -0.8057926 -1.7381574]]\n",
      "\n",
      "[[-2.5827851 -1.8746722  5.212584 ]\n",
      " [-3.512387  -1.6115853 -3.4763148]]\n"
     ]
    }
   ],
   "source": [
    "weights = tf.Variable(tf.random_normal([2,3], stddev=2))\n",
    "\n",
    "weights_ = tf.Variable(weights.initialized_value() * 2.0)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    print(sess.run(weights))\n",
    "    print()\n",
    "    print(sess.run(weights_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Fix Value`**\n",
    "+ tf.`fill`(dims, value, name=None)\n",
    "+ tf.`zeros`(shape, dtype=tf.float32, name=None) / tf.`ones`( )\n",
    "+ tf.`zeros_like`(tensor, dtype=None, name=None, optimize=True) / tf.`ones_like`( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 1]\n",
      " [1 1 1 1]\n",
      " [1 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "f_one = tf.fill([3,4], 1)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(f_one))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "\n",
      "(3, 4)\n",
      "(4, 4)\n"
     ]
    }
   ],
   "source": [
    "ones = tf.ones([4,4])\n",
    "zeros = tf.zeros([3,4])\n",
    "zeros_l = tf.zeros_like(ones)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    print(sess.run(zeros))\n",
    "    print(sess.run(zeros_l))\n",
    "    print()\n",
    "    print(zeros.get_shape())\n",
    "    print(zeros_l.get_shape())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Sequence`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **`tf.linspace(start, stop, num, name=None)`**\n",
    "    + 在 [start,stop] 范围内产生 num 个数的等差数列\n",
    "    + start & stop 要用浮点数表示\n",
    "    \n",
    "+ **`tf.range(start, limit=None, delta=1, dtype=None, name='range')`**\n",
    "    + 在 [start,limit) 范围内以步进值 delta 产生等差数列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 2. 3. 4. 5.]\n",
      "[1 2 3 4]\n"
     ]
    }
   ],
   "source": [
    "x = tf.linspace(start=1.0, stop=5.0, num=5, name=None)\n",
    "y = tf.range(start=1,limit=5, delta=1)\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(x))\n",
    "    print(sess.run(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Random Value`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **`tf.random_normal(shape, mean=0.0, stddev=1.0, dtype=tf.float32, seed=None, name=None)`**\n",
    "    + Outputs random values from a normal distribution.\n",
    "    + 正态分布"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **`tf.truncated_normal(shape, mean=0.0, stddev=1.0, dtype=tf.float32, seed=None, name=None)`**\n",
    "    + Outputs random values from a truncated normal distribution.\n",
    "    + 截断正态分布，只保留 [mean-2*stddev, mean+2*stddev] 内的随机数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **`tf.random_uniform(shape, minval=0, maxval=None, dtype=tf.float32, seed=None, name=None)`**\n",
    "    + Outputs random values from a uniform distribution.\n",
    "    + 均匀分布 : [minval, maxval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`initializer`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ tf.ones_initializer(dtype=tf.float32)\n",
    "+ tf.zeros_initializer(dtype=tf.float32)\n",
    "+ tf.constant_initializer(value=0, dtype=tf.float32, verify_shape=False)\n",
    "+ tf.random_uniform_initializer(minval=0, maxval=None, seed=None, dtype=tf.float32)\n",
    "+ tf.random_normal_initializer(mean=0.0, stddev=1.0, seed=None, dtype=tf.float32)\n",
    "+ tf.truncated_normal_initializer(mean=0.0, stddev=1.0, seed=None, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph & Session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Tensorflow 中的每一个计算都是计算图上的一个节点，而节点之间的边描述了计算之间的依赖关系\n",
    "\n",
    "\n",
    "+ Tensorflow 程序中，系统会自动维护一个默认的计算图\n",
    "    + **`tf.get_default_graph()`**：获取当前默认的计算图\n",
    "    + **`Tensor.graph`**：查看张量所属的计算图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.constant(1)\n",
    "a.graph is tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **`tf.Graph()`**:生成新的计算图\n",
    "    + `with tf.Graph().as_default()`\n",
    "    + `with tf.Session(graph=…) as sess:`\n",
    "\n",
    "\n",
    "+ **`不同计算图上的 \"张量 & 运算\" 都不会共享`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.] in Graph-01\n",
      "[1.] in Graph-02\n"
     ]
    }
   ],
   "source": [
    "g1 = tf.Graph()\n",
    "with g1.as_default():\n",
    "    v = tf.get_variable('var_03', initializer=tf.zeros(shape=[1]))\n",
    "\n",
    "g2 = tf.Graph()\n",
    "with g2.as_default():\n",
    "    v = tf.get_variable('var_03', initializer=tf.ones(shape=[1]))\n",
    "\n",
    "with tf.Session(graph=g1) as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    with tf.variable_scope(\"\", reuse=True):\n",
    "        print(sess.run(tf.get_variable('var_03')), \"in Graph-01\")\n",
    "\n",
    "with tf.Session(graph=g2) as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    with tf.variable_scope(\"\", reuse=True):\n",
    "        print(sess.run(tf.get_variable('var_03')), \"in Graph-02\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Session / 会话`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ `会话拥有并管理 Tensorflow 程序运行时的所有资源`\n",
    "\n",
    "\n",
    "+ 当所有计算完成之后，需要关闭会话来帮助系统回收资源，否则就可能出现资源泄露的问题\n",
    "    + Method.01 : 明确调用会话生成和关闭函数\n",
    "    + Method.02 : 为了解决异常退出时，资源释放的问题\n",
    "        + Tensorflow 可以通过 Python 的上下文管理器来使用会话\n",
    "        + 当上下文管理器退出时，则会自动释放所有资源"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Method-01`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "# sess.run(...)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Method-02`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 与 graph 不同的是, **`Tensorflow 不会自动生成默认的会话，而是需要手动指定`**\n",
    "    + `sess.as_default`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "[ True  True  True]\n",
      "[1 2 3]\n",
      "[1 2 3]\n"
     ]
    }
   ],
   "source": [
    "test = tf.constant([1,2,3], name='test')\n",
    "\n",
    "sess = tf.Session()\n",
    "with sess.as_default():\n",
    "    print(sess is tf.get_default_session())\n",
    "    \n",
    "    print(test.eval() == sess.run(test))\n",
    "    print(test.eval())\n",
    "    print(sess.run(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Tensor.eval() & tf.get_default_session().run(Tensor)`**\n",
    "+ **`sess.run() 可以一步获取多个tensor中的值`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([4, 6, 8]), array([ 3,  8, 15])]\n",
      "[4 6 8] [ 3  8 15]\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant([1, 2, 3], name='a')\n",
    "b = tf.constant([3, 4, 5], name='b')\n",
    "\n",
    "add = tf.add(a, b, name='add')\n",
    "mul = tf.multiply(a, b, name='mul')\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run([add, mul]))\n",
    "    print(add.eval(session=sess), mul.eval(session=sess))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.collection / 集合 / 整合资源"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 在一个计算图中，可以通过集合 collection 来管理不同类别的资源\n",
    "    + 资源类型：张量、变量\n",
    "\n",
    "    \n",
    "+ 通过 `tf.add_to_collection()` 可以将资源加入一个或多个集合中\n",
    "+ 然后通过 `tf.get_collection()` 获取一个集合里面的所有资源"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`tf.GraphKeys`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ tf.GraphKeys.**GLOBAL_VARIABLES**\n",
    "    + 默认的 Variable 对象集合，在分布式环境共性\n",
    "    + 使用场景：持久化 Tensorflow 模型\n",
    "\n",
    "\n",
    "+ tf.GraphKeys.**LOCAL_VARIABLES**\n",
    "    + 每台计算机的局部变量\n",
    "    + 通常用于临时变量，如：计数器\n",
    "    + 使用 tf.contrib.framework.local_variable 添加到此集合\n",
    "\n",
    "\n",
    "+ tf.GraphKeys.**MODEL_VARIABLES**\n",
    "    + 在构建模型时，所有用于正向传播的 Variable 都将添加到这里\n",
    "    + 使用 tf.contrib.framework.model_variable 添加到此集合\n",
    "\n",
    "\n",
    "+ tf.GraphKeys.**TRAINABLE_VARIABLES**\n",
    "    + 将有优化器训练的变量\n",
    "    + tf.trainable_variables()\n",
    "\n",
    "\n",
    "+ tf.GraphKeys.**SUMMARIES**\n",
    "    + 日志生成相关的张量\n",
    "    + Tensorflow 计算可视化\n",
    "\n",
    "\n",
    "+ tf.GraphKeys.**MOVING_AVERAGE_VARIABLES**\n",
    "    + 所有计算了滑动平均值的变量\n",
    "    + tf.moving_average_variables\n",
    "\n",
    "\n",
    "+ tf.GraphKeys.**REGULARIZATION_LOSSES**\n",
    "    + 收集在图构造期间正则化损失"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`tf.GraphKeys 使用`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# operation / op"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Property`**\n",
    "+ `Tensor.get_shape()`\n",
    "+ `tf.shape(tensor)` || sess.run()\n",
    "+ `tf.reshape(tensor, shape, name=None)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 4)\n"
     ]
    }
   ],
   "source": [
    "tensor = tf.Variable(tf.ones([3,4], dtype=tf.float32))\n",
    "print(tensor.get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 4]\n"
     ]
    }
   ],
   "source": [
    "# tf.shape() 函数本身也是返回一个张量，因而，需要用 sess.run() 来得到具体的值\n",
    "tensor = tf.Variable(tf.ones([3,4], dtype=tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(tf.shape(tensor)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 1)\n"
     ]
    }
   ],
   "source": [
    "tensor = tf.Variable(tf.ones([3,4], dtype=tf.float32))\n",
    "temp = tf.reshape(tensor, [-1,1])\n",
    "print(temp.get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "**`Basic Math Method`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.constant([[1,2,3],[1,2,3],[1,2,3],[1,2,3]], name='a')\n",
    "b = tf.constant([[3,4,5],[3,4,5],[3,4,5],[3,4,5]], name='b')\n",
    "\n",
    "result = tf.add(a,b, name='add')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "**`Implement Loop add one`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = tf.Variable(0, name='counter')\n",
    "one = tf.constant(1)\n",
    "new_value = tf.add(count, one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "**赋值op : tf.assign(old, new)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update = tf.assign(count, new_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    print(sess.run(count))\n",
    "    for _ in range(5):\n",
    "        sess.run(update)\n",
    "        print(sess.run(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product = tf.matmul(m1, m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "**`Statistics Method`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc on some axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor:输入\n",
    "    axis：在哪个维度进行 .. 操作\n",
    "    keepdims:是否保留原始数据的唯独，False 相当于执行完后，原始数据就会少一个维度\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all\n",
    "row\n",
    "column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reduce_all()\n",
    "计算tensor中各个元素的逻辑和（and运算）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reduce_any\n",
    "计算tensor中各个元素的逻辑或（or运算）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reduce_join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reduce_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reduce_mean(input_tensor, axis=None, keepdims=None, name=None, reduction_indices=None, keep_dims=None)\n",
    "Computes the mean of elements across dimensions of a tensor.\n",
    "Reduces `input_tensor` along the dimensions given in `axis`.\n",
    "Unless `keepdims` is true, the rank of the tensor is reduced by 1 for each\n",
    "entry in `axis`. If `keepdims` is true, the reduced dimensions\n",
    "are retained with length 1.\n",
    "\n",
    "If `axis` is None, all dimensions are reduced, and a\n",
    "tensor with a single element is returned.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Mean_12:0' shape=(2, 1) dtype=float32>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.constant([[1., 1., 1.], [2., 2., 2.]])\n",
    "tf.reduce_mean(x)  # 1.5\n",
    "tf.reduce_mean(x, 0)  # [1.5, 1.5, 1.5]\n",
    "tf.reduce_mean(x, 1)  # [1., 2.]\n",
    "tf.reduce_mean(x, 1, keepdims=True)  # [[1.], [2.]] / (2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reduce_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reduce_prod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`tf.reduce_sum`**(input_tensor, axis=None, keepdims=None, name=None, reduction_indices=None, keep_dims=None)\n",
    "+ Computes the sum of elements across dimensions of a tensor.\n",
    "+ keepdims: If true, retains reduced dimensions with length 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Sum_4:0' shape=() dtype=int32>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.constant([[1, 1, 1], [1, 1, 1]])\n",
    "tf.reduce_sum(x)  # 6\n",
    "tf.reduce_sum(x, 0)  # [2, 2, 2]\n",
    "tf.reduce_sum(x, 1)  # [3, 3]\n",
    "tf.reduce_sum(x, 1, keepdims=True)  # [[3], [3]]  tf.reduce_sum(x, 1, keepdims=True).get_shape()\n",
    "tf.reduce_sum(x, [0, 1])  # 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Assemble / Split data`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`tf.concat(values, axis, name='concat')`**\n",
    "+ Concatenates tensors along one dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  2  3]\n",
      " [ 4  5  6]\n",
      " [ 7  8  9]\n",
      " [10 11 12]]\n",
      "\n",
      "[[ 1  2  3  7  8  9]\n",
      " [ 4  5  6 10 11 12]]\n"
     ]
    }
   ],
   "source": [
    "t1 = [[1, 2, 3], [4, 5, 6]]\n",
    "t2 = [[7, 8, 9], [10, 11, 12]]\n",
    "\n",
    "t3 = tf.concat([t1, t2], 0)\n",
    "t4 = tf.concat([t1, t2], 1)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(t3))\n",
    "    print()\n",
    "    print(sess.run(t4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "+ **`tf.random_shuffle()`**\n",
    "tf.one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
