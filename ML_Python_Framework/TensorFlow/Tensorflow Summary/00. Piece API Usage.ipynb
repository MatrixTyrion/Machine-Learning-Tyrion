{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://blog.csdn.net/lenbow/article/details/52218551\n",
    "\n",
    "不仅可以优化更新训练的模型参数，也可以为`全局步骤 / global step`计数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_by_global_norm:修正梯度值\n",
    "    用于控制梯度爆炸的问题。梯度爆炸和梯度弥散的原因一样，都是因为链式法则求导的关系，导致梯度的指数级衰减。为了避免梯度爆炸，需要对梯度进行修剪。\n",
    "In [9]:\n",
    "\n",
    "gradients, vriables = zip(*optimizer.compute_gradients(goal))\n",
    "gradients, _ = tf.clip_by_global_norm(gradients, 1.25)\n",
    "train_step = optimizer.apply_gradients(zip(gradients, vriables))\n",
    "train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "exponential_decay 加入学习率衰减：\n",
    "In [10]:\n",
    "\n",
    "# global_step 记录当前是第几个batch\n",
    "global_step = tf.Variable(0)\n",
    "learning_rate = tf.train.exponential_decay(\n",
    "    3.0, global_step, 3, 0.3, staircase=True)\n",
    "optimizer2 = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "gradients, vriables = zip(*optimizer2.compute_gradients(goal))\n",
    "gradients, _ = tf.clip_by_global_norm(gradients, 1.25)\n",
    "train_step = optimizer2.apply_gradients(zip(gradients, vriables), \n",
    "                                       global_step=global_step)\n",
    "with tf.Session() as sess:\n",
    "        global_step.initializer.run()\n",
    "        x.initializer.run()\n",
    "        for i in range(10):\n",
    "            print \"x: \", x.eval()\n",
    "            train_step.run()\n",
    "            print \"goal: \",goal.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基本流程\n",
    "import tensorflow as tf\n",
    "from numpy.random import RandomState\n",
    "\n",
    "batch_size=8\n",
    "\n",
    "w1 = tf.Variable(tf.random_normal([2,3],stddev=1,seed=1))\n",
    "w2 = tf.Variable(tf.random_normal([3,1],stddev=1,seed=1))\n",
    "\n",
    "x = tf.placeholder(tf.float32,shape=(None,2),name='x_input')\n",
    "y_ = tf.placeholder(tf.float32,shape=(None,1),name ='y_input')\n",
    "\n",
    "a = tf.matmul(x,w1)\n",
    "y = tf.matmul(a,w2)\n",
    "\n",
    "#tf.clip_by_value()可以将计算的数值限制在一个范围内（1e-10~1.0）\n",
    "#y_表示真实值，y表示预测值，定义的是交叉熵损失函数\n",
    "#对于回归问题，最常用的损失函数是均方误差（MSE）mse = tf.reduce_mean(tf.square(y_-y))\n",
    "cross_entropy = -tf.reduce_mean(\n",
    "            y_*tf.log(tf.clip_by_value(y,1e-10,1.0)))\n",
    "#多分类问题适合softmax+cross_entrpy\n",
    "#cross_entropy2 = tf.nn.softmax_cross_entropy_with_logits(y,y_)\n",
    "train_step = tf.train.AdamOptimizer(0.001).minimize(cross_entropy)\n",
    "\n",
    "rdm = RandomState(1)\n",
    "dataset_size=128\n",
    "X = rdm.rand(dataset_size,2)\n",
    "Y = [[int(x1+x2<1)] for (x1,x2) in X]\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init_op = tf.initialize_all_variables()\n",
    "    sess.run(init_op)\n",
    "    \n",
    "    steps = 5000\n",
    "    for i in range(steps):\n",
    "        start = (i*batch_size)%dataset_size\n",
    "        end = min(start+batch_size,dataset_size)\n",
    "        \n",
    "        sess.run(train_step,feed_dict = {x:X[start:end],y_:Y[start:end]})\n",
    "        if i%1000==0:\n",
    "            total_cross_entropy = sess.run(\n",
    "                cross_entropy,feed_dict={x:X,y_:Y})\n",
    "            print(\"After %d training_step(s) ,cross_entropy on all data is %g\"%(i,total_cross_entropy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "学习率的设置 / 指数衰减法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过这个函数，可以先使用较大的学习率来快速得到一个比较优的解，然后随着迭代的继续逐步减小学习率，使得模型在训练后期更加稳定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decay_learning_rate = \\\n",
    "    learning_rate * dacay_rate ^ (global_step / decay_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decay_learning_rate 为每一轮优化时使用的学习率\n",
    "decay_steps 为衰减速度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "可以通过设置参数 staircase 选择不同的衰减方法大"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "staircase = False\n",
    "    学习率随迭代轮数变化为连续的\n",
    "staircase = True\n",
    "    gloabl_step / decay_step 会被转化为整数\n",
    "    这使得学习率成为一个阶梯函数 staircase function\n",
    "    \n",
    "        在这样的设置下，decay_steps 通常代表完成的使用一便训练数据所需要的迭代轮数\n",
    "        这个迭代轮数也就是总训练样本数除以每一个 batch 中的训练样本数\n",
    "        \n",
    "        这种设置的常用场景就是每完整地过完一遍训练数据，学习率就减小一次\n",
    "        这可以使得训练数据集中的所有数据对模型训练有相等的作用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "- 学习速率衰减\n",
    "    tf.train.exponential_decay\n",
    "- 过拟合 -> 正则化\n",
    "    tf.contrib.layers.l1_l2_regularizer\n",
    "    tf.get_collection\n",
    "    tf.add_to_collection\n",
    "    tf.add_n\n",
    "- ExponentialMovingAverage / 滑动平均模型\n",
    "    tf.train.ExponentialMovingAverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "**`tf.train.exponential_decay`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    global_step = tf.Variable(0)\n",
    "    \n",
    "    # 通过 exponential_decay 函数来生成学习率\n",
    "    leanring_rate = tf.train.exponential_decay(\n",
    "        0.1, global_step, decay_steps=100, decay_rate=0.96, staircase=True\n",
    "    )\n",
    "    \n",
    "    # 使用'指数衰减学习率'\n",
    "    # 在 minimize 函数中传入 global_step, 并将自动更新 global_step 参数\n",
    "    # 从而使得学习率也得到相应更新\n",
    "    optimizer = tf.train.GradientDescentOptimizer(leanring_rate)\n",
    "    learning_step = optimizer.minimize(...my_loss.., global_step=global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "**`Overfit`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "当一个模型过为复杂之后，它可以很好地'记忆'每一个训练数据中随机噪声的部分而忘记了要去'学习'训练数据中通用的趋势"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = tf.constant([[1.0, -2.0], [-3.0, 4.0]])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    l1 = tf.contrib.layers.l1_regularizer(.5)(weight)\n",
    "    l2 = tf.contrib.layers.l2_regularizer(.5)(weight)\n",
    "    l1_l2 = tf.contrib.layers.l1_l2_regularizer(.5, .5)(weight)\n",
    "    \n",
    "    print(sess.run(l1))\n",
    "    print(sess.run(l2))\n",
    "    print(sess.run(l1_l2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "```python\n",
    "w = tf.Variable(tf.random_normal([2,1], stddev=1, seed=1))\n",
    "y = tf.matmul(x, w)\n",
    "\n",
    "loss = tf.reduce_mean(tf.square(y_ - y))\n",
    "reg = tf.contrib.layers.l2_regularizer(lambda)(w)\n",
    "\n",
    "loss = loss + reg\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "使用 collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weight(shape, lambda):\n",
    "    reg = tf.contrib.layers.l2_regularizer(lambda)\n",
    "    \n",
    "    var = tf.Variable(tf.random_normal(shape), dtype=tf.float32)\n",
    "    tf.add_to_collection('loss', reg(var))\n",
    "    \n",
    "    return var\n",
    "\n",
    "x  = tf.placeholder(tf.float32, shape=(None, 2))\n",
    "y_ = tf.placeholder(tf.float32, shape=(None, 1))\n",
    "batch_size = 8\n",
    "\n",
    "# 每一层网络中的节点个数\n",
    "layer_dim = [2, 10, 10, 10, 1]\n",
    "# layers of NN\n",
    "n_layers = len(layer_dim)\n",
    "\n",
    "# 这个变量维护向前传播时最深层的节点，开始的时候就是输入层\n",
    "cur_layer = x\n",
    "# 当前层的节点个数\n",
    "in_dim = layer_dim[0]\n",
    "\n",
    "# 通过一个循环生成 5 层 FC-nn\n",
    "for i in range(1, n_layers):\n",
    "    out_dim = layer_dim[i]\n",
    "    weight = get_weight([in_dim, out_dim], 0.001)\n",
    "    bias = tf.Variable(tf.constant(0.1, shape=[out_dim]))\n",
    "    \n",
    "    cur_layer = tf.nn.relu(tf.matmul(cur_layer, weight) + bias)\n",
    "    in_dim = layer_dim[i]\n",
    "    \n",
    "mse_loss = tf.reduce_mean(tf.square(y_ - cur_layer))\n",
    "\n",
    "# 将均方误差加入到'loss'集合中\n",
    "tf.add_to_collection('loss', mse_loss)\n",
    "\n",
    "# tf.get_collection 返回一个列表，这个列表是所有这个集合中的元素\n",
    "loss = tf.add_n(tf.get_collection('loss'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,5):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Exponential Moving Average`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = tf.Variable(0, dtype=tf.float32)\n",
    "\n",
    "# 模拟社交网络迭代轮数, 动态控制衰减率\n",
    "step = tf.Variable(0, trainable=False)\n",
    "\n",
    "# 定义一个滑动平均累\n",
    "ema = tf.train.ExponentialMovingAverage(decay=0.99, num_updates=step)\n",
    "\n",
    "# 定义一个滑动平均的操作\n",
    "# 这里需要给定一个列表, 每次执行这个操作时, 列表里的元素都会被更新\n",
    "maintain_average_op = ema.apply([var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    \n",
    "    print(sess.run([var, ema.average(var)]))\n",
    "\n",
    "    # 更新v1的滑动平均值，衰减率为min{0.99,(1+step)/(10+step)=0.1}=0.1,\n",
    "    # 所以v1的滑动平均被更新为0.1*0+0.9*5=4.5\n",
    "    sess.run(tf.assign(var, 5))\n",
    "    sess.run(maintain_average_op)\n",
    "    print(sess.run([var, ema.average(var)]))\n",
    "    \n",
    "    # decay = min{0.99, (1+step)/(10+step)} = 0.99\n",
    "    # 0.99 * 4.5 + 0.01 * 10 = 4.555\n",
    "    sess.run(tf.assign(step, 10000))\n",
    "    sess.run(tf.assign(var, 10))\n",
    "    sess.run(maintain_average_op)\n",
    "    print(sess.run([var, ema.average(var)]))\n",
    "    \n",
    "    # 0.99 * 4.555 + 0.01 * 10\n",
    "    sess.run(maintain_average_op)\n",
    "    print(sess.run([var, ema.average(var)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在初始化 ExponentialMovingAverage 时，需要提供一个衰减率 'decay'\n",
    "这个衰减率将用于控制模型更新的速度\n",
    "ExponentialMovingAverage 对每一个变量会维护一个影子变量 (shadow variable), 这个影子变量的初始值就是相应变量的初始值，而每次运行变量更新时，影子变量的值会更新为：\n",
    "    shadow_variable = decay * shadow_variable + (1-decay) * variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shadow_variable 影子变量\n",
    "variable 带更新的变量\n",
    "decay 衰减率，decay 决定了模型更新的速度，decay 越大模型越趋于稳定，一般将其设定为接近于 1 的数，(0.999，0.9999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "为了使得模型在训练前期可以更新的更快，ExponentialMovingAverage 还提供了 num_updates 参数\n",
    "min{decay, (1+num_updates)/(10+num_updates)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-83231f068ae1>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Matrix\\Jupyter\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Matrix\\Jupyter\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Matrix\\Jupyter\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Matrix\\Jupyter\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Matrix\\Jupyter\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-4-ba8ee6aad98e>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-4-ba8ee6aad98e>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    通过 input_data.read_data_sets 函数生成的类会自动将 MNIST 数据集划分为 train、validation、test 三个数据集\u001b[0m\n\u001b[1;37m                ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "通过 input_data.read_data_sets 函数生成的类会自动将 MNIST 数据集划分为 train、validation、test 三个数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainning data size: 55000\n",
      "Validating data size: 5000\n",
      "Testing data size: 10000\n",
      "Example traingning data label: [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "Trainning data shape: (55000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(\"Trainning data size:\", mnist.train.num_examples)\n",
    "print(\"Validating data size:\", mnist.validation.num_examples)\n",
    "print(\"Testing data size:\", mnist.test.num_examples)\n",
    "\n",
    "#print(\"Example trainning data:\", mnist.train.images[0])\n",
    "print(\"Example traingning data label:\", mnist.train.labels[0])\n",
    "\n",
    "print(\"Trainning data shape:\", mnist.train.images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "为了方便使用随机梯度下降，input_data.read_data_sets 函数生成的类还提供了 minist.train.next_batch 函数\n",
    "它可以从所有的训练数据中读取一小部分作为一个训练 batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (100, 784)\n",
      "Y shape: (100, 10)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "xs, ys = mnist.train.next_batch(batch_size)\n",
    "\n",
    "print(\"X shape:\", xs.shape)\n",
    "print(\"Y shape:\", ys.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_NODE = 784\n",
    "OUTPUT_NODE = 10\n",
    "\n",
    "LAYER1_NODE = 500\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "LEARNING_RATE_BASE  = 0.8\n",
    "LEARNING_RATE_DECAY = 0.99\n",
    "\n",
    "REGULARIZATION_RATE = 0.0001\n",
    "TRAINING_STEPS = 30000\n",
    "MOVING_AVERAGE_DECAY = 0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "5.2.1 Tensorflow MNIST Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "虽然一个神经网络模型的效果最终是通过测试数据来评判的，但是我们不能直接通过模型在测试数据上的效果来选择参数\n",
    "使用测试数据来选取参数可能会导致神经网络模型过度拟合测试数据，从而失去了对为止数据的预判能力"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "不同问题的数据分布不一样，如果验证数据分布不能很好地代表测试数据分布，那么模型在这两个数据集上的表现就有可能不一样\n",
    "\n",
    "一般来说选取的验证数据分布越接近测试数据分布，模型在验证数据上的表现越可以体现模型在测试数据上的表现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 不同模型效果比较"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Chapter.04 - Optimizer 5 method\n",
    "- 神经网络结构设计上\n",
    "    激活函数\n",
    "    多层隐藏层\n",
    "- 神经网络优化\n",
    "    指数衰减的学习率\n",
    "    加入正则化的损失函数\n",
    "    滑动平均模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用 '滑动平均模型、指数衰减的学习率、正则化' 带来的正确率的提升并不是很明显\n",
    "\n",
    "是因为 '滑动平均模型和指数衰减的学习率' 在一定程度上都是限制神经网络中参数更新的速度\n",
    "\n",
    "当问题更加复杂时，迭代不会这么快接近收敛，这时滑动平均模型和指数衰减的学习率可以发挥更大的作用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55000, 784) (55000, 10)\n",
      "(10000, 784) (10000, 10)\n",
      "(5000, 784) (5000, 10)\n",
      "0.9196\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(mnist.train.images.shape, mnist.train.labels.shape)\n",
    "print(mnist.test.images.shape, mnist.test.labels.shape)\n",
    "print(mnist.validation.images.shape, mnist.validation.labels.shape)\n",
    "\n",
    "import tensorflow as tf\n",
    "sess = tf.InteractiveSession()\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "\n",
    "W = tf.Variable(tf.zeros([784, 10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "y = tf.nn.softmax(tf.matmul(x, W) + b)\n",
    "\n",
    "y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))\n",
    "\n",
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
    "\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "for i in range(1000):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "    train_step.run({x: batch_xs, y_: batch_ys})\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "print(accuracy.eval({x: mnist.test.images, y_: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "\n",
    "t = np.linspace(0, math.pi, 1000)\n",
    "x = np.sin(t)\n",
    "y = np.cos(t) + np.power(x, 2.0/3)\n",
    "plt.plot(x, y, color='red', linewidth=2)\n",
    "plt.plot(-x, y, color='red', linewidth=2)\n",
    "plt.ylim(-2, 2)\n",
    "plt.xlim(-2, 2)\n",
    "plt.axis('off')\n",
    "plt.title(\"my heart will go on\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
